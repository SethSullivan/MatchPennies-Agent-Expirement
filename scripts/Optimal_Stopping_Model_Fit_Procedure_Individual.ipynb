{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nv4 Uses the object imported from the py file class which is very similar to the Optimal_Stopping_Function_v3\\n\\nAs of 1/13/23, the only change is the addition of the decision to action delay\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dill\n",
    "import importlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import data_visualization as dv\n",
    "import copy\n",
    "import numba as nb\n",
    "import time\n",
    "\n",
    "import src.read_data_functions as rdf\n",
    "import src.plot_functions as pf\n",
    "import src.Optimal_Stopping_Object as oso\n",
    "import src.Subject_Object_v2\n",
    "\n",
    "%load_ext autoreload\n",
    "%aimport Optimal_Stopping_Object\n",
    "%autoreload 1\n",
    "'''\n",
    "v4 Uses the object imported from the py file class which is very similar to the Optimal_Stopping_Function_v3\n",
    "\n",
    "As of 1/13/23, the only change is the addition of the decision to action delay\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = slice(10,50)\n",
    "a = np.ones(100)\n",
    "a[s]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Exp1 or Exp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"Exp1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Thangs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.use(\"cashaback_dark\")\n",
    "wheel = dv.ColorWheel()\n",
    "\n",
    "# Initial thangs\n",
    "os.chdir(f\"D:\\OneDrive - University of Delaware - o365\\Subject_Data\\MatchPennies_Agent_{experiment}\")\n",
    "PATH = os.getcwd()\n",
    "SAVE_PATH = f\"D:\\\\OneDrive - University of Delaware - o365\\\\Subject_Data\\\\MatchPennies_Agent_{experiment}\\\\Figures\\\\\"\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "\n",
    "# Fields pull and pull list\n",
    "figures_pull_list = []\n",
    "figures_pull_list_control = []\n",
    "figures_pull_list_task = []\n",
    "fields_pull = []\n",
    "with open(PATH + \"\\\\Figures_Pull_List.txt\", \"r\") as pull_file:\n",
    "    figures_pull_list = pull_file.read().splitlines()\n",
    "with open(PATH + \"\\\\Fields_Pull.txt\", \"r\") as fields_pull:\n",
    "    fields_pull = fields_pull.read().splitlines()\n",
    "num_subjects = len(figures_pull_list)\n",
    "if experiment == \"Exp2\":\n",
    "    tp3_title = \"Win = 1\\nIncorrect = 0\\nIndecision = 0\"\n",
    "    tp4_title = \"Win = 1\\nIncorrect = -1\\nIndecision = 0\"\n",
    "    tp5_title = \"Win = 1\\nIncorrect = 0\\nIndecision = -1\"\n",
    "    tp6_title = \"Win = 1\\nIncorrect = -1\\nIndecision = -1\"\n",
    "    trial_block_titles = [tp3_title, tp4_title, tp5_title, tp6_title]\n",
    "    num_blocks = len(trial_block_titles)\n",
    "    xlabel = \"Payoff Condition\"\n",
    "if experiment == \"Exp1\":\n",
    "    tp3_title = \"1000 (50)\"\n",
    "    tp4_title = \"1000 (150)\"\n",
    "    tp5_title = \"1100 (50)\"\n",
    "    tp6_title = \"1100 (150)\"\n",
    "    tp7_title = \"1200 (50)\"\n",
    "    tp8_title = \"1200 (150)\"\n",
    "    trial_block_titles = [tp3_title, tp4_title, tp5_title, tp6_title, tp7_title, tp8_title]\n",
    "    num_blocks = len(trial_block_titles)\n",
    "    xlabel = \"Mean [SD] Agent Decision Time (ms)\"\n",
    "num_subjects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub1\n",
      "Sub2\n",
      "Sub3\n",
      "Sub4\n",
      "Sub5\n",
      "Sub6\n",
      "Sub7\n",
      "Sub8\n",
      "Sub9\n",
      "Sub10\n",
      "Sub11\n",
      "Sub12\n",
      "Sub13\n",
      "Sub14\n",
      "Sub15\n",
      "Sub16\n",
      "Sub17\n",
      "Sub18\n",
      "Sub19\n",
      "Sub20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\src\\Subject_Object_v2.py:557: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.mu_s = (self.phat_correct*self.mhat_correct - self.phat_error*self.mhat_error)/(self.phat_correct - self.phat_error)\n",
      "D:\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\src\\Subject_Object_v2.py:568: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.mu_s_alternate = (self.phat_correct*self.mhat_correct_alternate - self.phat_error*self.mhat_error_alternate)/(self.phat_correct - self.phat_error)\n"
     ]
    }
   ],
   "source": [
    "if \"subject_objects\" not in locals():\n",
    "    subject_objects = rdf.generate_subject_objects(experiment)\n",
    "    subject_objects2 = copy.deepcopy(subject_objects)\n",
    "    # group = Subject_Object_v2.Group(subject_objects, select_trials = 'All Trials', num_stds_for_reaction_time = 2,\n",
    "    #                                     task_leave_time_metric_name = 'player_pos_task_leave_time', task_movement_time_metric_name = 'player_pos_task_movement_time',\n",
    "    #                                     reaction_time_metric_name = 'player_pos_reaction_time', reaction_movement_time_metric_name = 'player_pos_reaction_movement_time')\n",
    "    # group.analyze_data()\n",
    "    group = Subject_Object_v2.Group(\n",
    "        subject_objects2,\n",
    "        select_trials=\"All Trials\",\n",
    "        num_stds_for_reaction_time=2,\n",
    "        task_leave_time_metric_name=\"player_velocity_task_leave_time_thresh\",\n",
    "        task_movement_time_metric_name=\"player_velocity_task_movement_time_thresh\",\n",
    "        reaction_time_metric_name=\"player_velocity_reaction_time_thresh\",\n",
    "        reaction_movement_time_metric_name=\"player_velocity_reaction_movement_time_thresh\",\n",
    "    )\n",
    "    group.analyze_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run fit sequence for each individual  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelConstructor' object has no attribute 'initial_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 81\u001b[0m\n\u001b[0;32m     74\u001b[0m targets \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\n\u001b[0;32m     75\u001b[0m     [np\u001b[39m.\u001b[39mnanmedian(group\u001b[39m.\u001b[39mplayer_task_leave_time, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)[i], \n\u001b[0;32m     76\u001b[0m     group\u001b[39m.\u001b[39mplayer_perc_wins[i], \n\u001b[0;32m     77\u001b[0m     group\u001b[39m.\u001b[39mplayer_perc_incorrects[i], \n\u001b[0;32m     78\u001b[0m     group\u001b[39m.\u001b[39mplayer_perc_indecisions[i]]\n\u001b[0;32m     79\u001b[0m )\n\u001b[0;32m     80\u001b[0m metric_keys \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mwtd_leave_target_time\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mprob_win\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mprob_incorrect\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mprob_indecision\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 81\u001b[0m fit_params,out \u001b[39m=\u001b[39m model_true\u001b[39m.\u001b[39;49mfit_multiple_parameters(\n\u001b[0;32m     82\u001b[0m         free_params_init\u001b[39m=\u001b[39;49mfree_params_init,\n\u001b[0;32m     83\u001b[0m         targets\u001b[39m=\u001b[39;49mtargets,\n\u001b[0;32m     84\u001b[0m         metric_keys\u001b[39m=\u001b[39;49mmetric_keys,\n\u001b[0;32m     85\u001b[0m     )\n\u001b[0;32m     86\u001b[0m \u001b[39m# Fit true model the old way\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39m# model_true.fit_model(\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39m#     model_true.player_behavior.wtd_leave_target_time,\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39m#     np.nanmedian(group.player_task_leave_time, axis=2)[i],\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m# Update dicts\u001b[39;00m\n\u001b[0;32m     92\u001b[0m model_true_list\u001b[39m.\u001b[39mupdate({subname: model_true})\n",
      "File \u001b[1;32md:\\onedrive - university of delaware - o365\\desktop\\matchpennies-agent-expirement\\src\\Optimal_Stopping_Object.py:583\u001b[0m, in \u001b[0;36mModelConstructor.fit_multiple_parameters\u001b[1;34m(self, free_params_init, metric_keys, targets)\u001b[0m\n\u001b[0;32m    581\u001b[0m initial_guess \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(free_params_init\u001b[39m.\u001b[39mvalues()))\n\u001b[0;32m    582\u001b[0m \u001b[39m# self.initial_shape = initial_guess.shape\u001b[39;00m\n\u001b[1;32m--> 583\u001b[0m out \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39;49mminimize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfree_param_loss, initial_guess, args\u001b[39m=\u001b[39;49m(metric_keys, targets, free_params_init\u001b[39m.\u001b[39;49mkeys()), \n\u001b[0;32m    584\u001b[0m                         method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mNelder-Mead\u001b[39;49m\u001b[39m\"\u001b[39;49m, bounds\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, tol \u001b[39m=\u001b[39;49m \u001b[39m0.00000001\u001b[39;49m)\n\u001b[0;32m    585\u001b[0m \u001b[39m# ans = out.x + np.min(self.inputs.timesteps)\u001b[39;00m\n\u001b[0;32m    586\u001b[0m ans \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_shape)\n",
      "File \u001b[1;32mc:\\Users\\Seth Sullivan\\anaconda3\\envs\\aim1\\lib\\site-packages\\scipy\\optimize\\_minimize.py:611\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     constraints \u001b[39m=\u001b[39m standardize_constraints(constraints, x0, meth)\n\u001b[0;32m    610\u001b[0m \u001b[39mif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnelder-mead\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_neldermead(fun, x0, args, callback, bounds\u001b[39m=\u001b[39mbounds,\n\u001b[0;32m    612\u001b[0m                                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    613\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpowell\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_powell(fun, x0, args, callback, bounds, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\Seth Sullivan\\anaconda3\\envs\\aim1\\lib\\site-packages\\scipy\\optimize\\optimize.py:750\u001b[0m, in \u001b[0;36m_minimize_neldermead\u001b[1;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, bounds, **unknown_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m fsim \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((N \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,), \u001b[39mfloat\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m--> 750\u001b[0m     fsim[k] \u001b[39m=\u001b[39m func(sim[k])\n\u001b[0;32m    752\u001b[0m ind \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(fsim)\n\u001b[0;32m    753\u001b[0m fsim \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtake(fsim, ind, \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Seth Sullivan\\anaconda3\\envs\\aim1\\lib\\site-packages\\scipy\\optimize\\optimize.py:464\u001b[0m, in \u001b[0;36m_wrap_function.<locals>.function_wrapper\u001b[1;34m(x, *wrapper_args)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunction_wrapper\u001b[39m(x, \u001b[39m*\u001b[39mwrapper_args):\n\u001b[0;32m    463\u001b[0m     ncalls[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 464\u001b[0m     \u001b[39mreturn\u001b[39;00m function(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49m(wrapper_args \u001b[39m+\u001b[39;49m args))\n",
      "File \u001b[1;32md:\\onedrive - university of delaware - o365\\desktop\\matchpennies-agent-expirement\\src\\Optimal_Stopping_Object.py:590\u001b[0m, in \u001b[0;36mModelConstructor.free_param_loss\u001b[1;34m(self, free_params_values, metric_keys, targets, free_params_keys)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfree_param_loss\u001b[39m(\u001b[39mself\u001b[39m, free_params_values, metric_keys, targets, free_params_keys):\n\u001b[1;32m--> 590\u001b[0m     free_params_values \u001b[39m=\u001b[39m free_params_values\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitial_shape) \u001b[39m# Reshape array\u001b[39;00m\n\u001b[0;32m    591\u001b[0m     \u001b[39m# Create dictionary back\u001b[39;00m\n\u001b[0;32m    592\u001b[0m     d \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(free_params_keys,free_params_values))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ModelConstructor' object has no attribute 'initial_shape'"
     ]
    }
   ],
   "source": [
    "if experiment == \"Exp1\":\n",
    "    rt = np.nanmedian(group.reaction_time, axis=1) - 15\n",
    "    rt_sd = np.nanstd(group.reaction_time, axis=1)\n",
    "elif experiment == \"Exp2\":\n",
    "    rt    = np.nanmedian(group.react_reaction_time_only_react, axis=1) - 30\n",
    "    rt_sd = np.nanmedian(np.nanstd(group.reaction_time, axis=2))\n",
    "\n",
    "mt                   = np.min(np.nanmedian(group.player_task_movement_time, axis=2), axis=1)  # Get movement time for the condition where they tried the hardest\n",
    "mt_sd                = np.median(np.nanstd(group.player_task_movement_time, axis=2), axis=1)\n",
    "time_sd              = np.array([(np.nanstd(group.coincidence_reach_time, axis=1))] * num_blocks).T\n",
    "perc_wins_both_reach = group.perc_gamble_wins_when_both_decide\n",
    "gamble_sd            = np.nanstd(group.player_gamble_task_leave_time, axis=2)\n",
    "agent_sds            = np.nanstd(group.agent_task_leave_time, axis=2)\n",
    "agent_means          = np.nanmean(group.agent_task_leave_time, axis=2)\n",
    "\n",
    "model_expected_list = {}\n",
    "model_true_list = {}\n",
    "for i in range(1):\n",
    "    subname = figures_pull_list[i]\n",
    "    # model_expected = oso.ModelConstructor(\n",
    "    #     experiment=experiment,\n",
    "    #     num_blocks=num_blocks,\n",
    "    #     num_timesteps=1800,\n",
    "    #     BETA_ON=False,\n",
    "    #     agent_means=agent_means[i, :],\n",
    "    #     agent_sds=agent_sds[i, :],\n",
    "    #     reaction_time={\"true\": rt[i], \"exp\": rt[i]},\n",
    "    #     movement_time={\"true\": mt[i], \"exp\": mt[i]},\n",
    "    #     reaction_sd={\"true\": rt_sd[i], \"exp\": rt_sd[i]},\n",
    "    #     movement_sd={\"true\": mt_sd[i], \"exp\": mt_sd[i]},\n",
    "    #     timing_sd={\"true\": time_sd[i], \"exp\": time_sd[i]},\n",
    "    #     perc_wins_when_both_reach=perc_wins_both_reach[i],\n",
    "    #     gamble_delay_known=True,\n",
    "    #     gamble_sd_known=True,\n",
    "    #     gamble_decision_sd={\"true\": gamble_sd[i], \"exp\": 10},\n",
    "    #     gamble_delay={\"true\": 125, \"exp\": 50},\n",
    "    #     expected=True,\n",
    "    # )\n",
    "\n",
    "    model_true = oso.ModelConstructor(\n",
    "        experiment=experiment,\n",
    "        num_blocks=num_blocks,\n",
    "        num_timesteps=1800,\n",
    "        BETA_ON=False,\n",
    "        agent_means=agent_means[i, :],\n",
    "        agent_sds=agent_sds[i, :],\n",
    "        reaction_time={\"true\": rt[i], \"exp\": rt[i]},\n",
    "        movement_time={\"true\": mt[i], \"exp\": mt[i]},\n",
    "        reaction_sd={\"true\": rt_sd[i], \"exp\": rt_sd[i]},\n",
    "        movement_sd={\"true\": mt_sd[i], \"exp\": mt_sd[i]},\n",
    "        timing_sd={\"true\": time_sd[i], \"exp\": time_sd[i]},\n",
    "        perc_wins_when_both_reach=perc_wins_both_reach[i],\n",
    "        gamble_delay_known=True,\n",
    "        gamble_sd_known=True,\n",
    "        gamble_decision_sd={\"true\": gamble_sd[i], \"exp\": 10},\n",
    "        gamble_delay={\"true\": 125, \"exp\": 50},\n",
    "        expected=False,\n",
    "        data_leave_times=np.nanmedian(group.player_task_leave_time, axis=2)[i],\n",
    "    )\n",
    "\n",
    "    # Fit true model\n",
    "    free_params_init = {\n",
    "                        'reaction_time':model_true.inputs.reaction_time['true'],\n",
    "                        }\n",
    "    # get_true_metric = model_true.results.get_metric\n",
    "    # init_decision_time = np.array([900]*num_blocks)\n",
    "    # init_model_leave_time = get_true_metric(model_true.player_behavior.wtd_leave_target_time, metric_type=\"optimal\")\n",
    "    # init_model_wins       = get_true_metric(model_true.score_metrics.prob_win, metric_type=\"optimal\")\n",
    "    # init_model_incorrects       = get_true_metric(model_true.score_metrics.prob_incorrect, metric_type=\"optimal\")\n",
    "    # init_model_indecisions       = get_true_metric(model_true.score_metrics.prob_indecision, metric_type=\"optimal\")\n",
    "\n",
    "    # init_model_metrics = np.array([init_decision_time,init_model_leave_time,init_model_wins,init_model_incorrects,init_model_indecisions])\n",
    "\n",
    "    targets = np.array(\n",
    "        [np.nanmedian(group.player_task_leave_time, axis=2)[i], \n",
    "        group.player_perc_wins[i], \n",
    "        group.player_perc_incorrects[i], \n",
    "        group.player_perc_indecisions[i]]\n",
    "    )\n",
    "    metric_keys = ['wtd_leave_target_time','prob_win','prob_incorrect','prob_indecision']\n",
    "    fit_params,out = model_true.fit_multiple_parameters(\n",
    "            free_params_init=free_params_init,\n",
    "            targets=targets,\n",
    "            metric_keys=metric_keys,\n",
    "        )\n",
    "    # Fit true model the old way\n",
    "    # model_true.fit_model(\n",
    "    #     model_true.player_behavior.wtd_leave_target_time,\n",
    "    #     np.nanmedian(group.player_task_leave_time, axis=2)[i],\n",
    "    # )\n",
    "    # Update dicts\n",
    "    model_true_list.update({subname: model_true})\n",
    "    # model_expected_list.update({subname: model_expected})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1149.45877498, 1166.5       , 1214.87571813, 1120.19065671,\n",
       "       1112.42926777, 1220.20788839])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#TODO figure out this weirdness\n",
    "model_true.results.get_metric(model_true.player_behavior.wtd_leave_target_time,metric_type='fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1149.5, 1166.5, 1215. , 1120. , 1112.5, 1220. ])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmedian(group.player_task_leave_time,axis=2)[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.2343084 ,   2.96155529,  -2.9520296 ,  -9.03979225,\n",
       "        -9.15985113,  -3.42491119])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_true.results.get_metric(model_true.score_metrics.prob_incorrect,metric_type='fit')*100 - group.player_perc_incorrects[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26133779, -4.80319278,  9.17810366,  2.92205253,  5.76777487,\n",
       "        8.02916781])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_true.results.get_metric(model_true.score_metrics.prob_indecision,metric_type='fit')*100 - group.player_perc_indecisions[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[213.40494526],\n",
       "       [213.40494526]]), array([594.63478422, 594.63478422]))\n",
       "           fun: 594.6347842188381\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 76\n",
       "           nit: 36\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([213.40494526])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aim1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

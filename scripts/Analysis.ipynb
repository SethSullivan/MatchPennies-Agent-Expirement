{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import dill\n",
    "from tqdm import tqdm \n",
    "from scipy.signal import find_peaks\n",
    "import sys\n",
    "import io\n",
    "\n",
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Thangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'D:\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement')\n",
    "import filter_functions as ff\n",
    "from matplotlib.pyplot import cm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'Exp2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields pull and pull list\n",
    "os.chdir(f'D:\\OneDrive - University of Delaware - o365\\Subject_Data\\MatchPennies_Agent_{experiment}')\n",
    "PATH = os.getcwd()\n",
    "if experiment == 'Exp2':\n",
    "    analysis_pull_list = []\n",
    "    with open(\"Analysis_Pull_List.txt\", \"r\") as file:\n",
    "        analysis_pull_list = file.read().splitlines()\n",
    "    analysis_pull_list_reaction = [s+'_Reaction' for s in analysis_pull_list]\n",
    "    analysis_pull_list_timing = [s+'_Timing' for s in analysis_pull_list]\n",
    "    analysis_pull_list_task = [s+'_Task' for s in analysis_pull_list]\n",
    "else:\n",
    "    analysis_pull_list = []\n",
    "    with open('Analysis_Pull_List.txt','r') as file:\n",
    "        analysis_pull_list = file.read().splitlines()\n",
    "    analysis_pull_list_control = [s+'_Control' for s in analysis_pull_list]\n",
    "    analysis_pull_list_task = [s+'_Task' for s in analysis_pull_list]\n",
    "    \n",
    "with open(\"Fields_Pull.txt\", \"r\") as fields_pull:\n",
    "    fields_pull = fields_pull.read().splitlines()\n",
    "    \n",
    "num_subjects = len(analysis_pull_list)\n",
    "task_name = f'Matchpennies_Agent_{experiment}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target information\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Row 0 = Start Target\n",
    "\n",
    "- Row 1 = Left screen, right target x pos (left target is 2\\*startx - right targetx)\n",
    "\n",
    "- Dim 1 = Radius\n",
    "\n",
    "- Dim 2 = Thickness of the circle edge (don't know if this matters)\n",
    "\n",
    "Dataframe is in centimeters, so need to divide everything by 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment == 'Exp2':\n",
    "    file = 'Sub1_Reaction\\\\Sub1_ReactionTarget_Table.csv'\n",
    "else:\n",
    "    file = 'Sub1_Control\\\\Sub1_ControlTarget_Table.csv'\n",
    "    \n",
    "df = pd.read_csv(file)\n",
    "df[\"X\"] = df[\"X\"]/100\n",
    "df[\"Y\"] = df[\"Y\"]/100\n",
    "df['Dim 1'] = df['Dim 1']/100 # Target table is in centimeters, I guess this doesn't matter but it makes me feel better\n",
    "df['Dim 2'] = df['Dim 2']/100\n",
    "# Target information for Right Hand (keeping this because the positions of target 3 and 4 are based on target 1 and start 1)\n",
    "startx = df.loc[0]['X']\n",
    "starty = df.loc[0]['Y']\n",
    "start_radius = df.loc[0]['Dim 1'] \n",
    "adjusted_start_radius = start_radius*1.0 # ! This determines what size target I use to determine target leave time \n",
    "\n",
    "target1x = df.loc[1]['X']\n",
    "target1y = df.loc[1]['Y']\n",
    "target1_radius = df.loc[1]['Dim 1']\n",
    "\n",
    "target2x = 2*startx - target1x\n",
    "target2y = target1y\n",
    "target2_radius = target1_radius\n",
    "\n",
    "# Timing target\n",
    "timing_targetx = startx\n",
    "timing_targety = target1y\n",
    "timing_target_pos = np.sqrt(timing_targetx**2 + timing_targety**2)\n",
    "timing_target_radius = target1_radius   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Reaction Task Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set PICKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if experiment == 'Exp1':\n",
    "#     coincidence_trials = 50\n",
    "#     interval_trials = 50\n",
    "#     reaction_trials = 50\n",
    "#     reaction_blocks = 1\n",
    "#     trial_time = 5000\n",
    "#     num_blocks = 6\n",
    "#     num_trials = 80\n",
    "# elif experiment == 'Exp2':\n",
    "#     coincidence_trials = 50\n",
    "#     interval_trials = 50\n",
    "#     reaction_trials = 100\n",
    "#     reaction_blocks = 3\n",
    "#     trial_time = 8000\n",
    "#     num_blocks = 4\n",
    "#     num_trials = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Sub20_Reaction\n",
      "1 Sub23_Reaction\n",
      "2 Sub24_Reaction\n",
      "3 Sub25_Reaction\n",
      "4 Sub26_Reaction\n",
      "5 Sub27_Reaction\n"
     ]
    }
   ],
   "source": [
    "#%% Get reaction time data\n",
    "#! Reaction for Exp2 is 3 blocks, with 0=Mix,1=React Only,2=Gamble Only\n",
    "#! Reaction for Exp1 is 3 blocks, with 1=React(two circles),2=Interval,3=Coincidence\n",
    "\n",
    "if experiment == 'Exp2':\n",
    "    filename = f'Sub1_Reaction\\\\Sub1_ReactionBlock_Table.csv'\n",
    "    trial_time = 8000\n",
    "else:\n",
    "    filename = f'Sub1_Control\\\\Sub1_ControlBlock_Table.csv'\n",
    "    trial_time = 5000\n",
    "    \n",
    "block_table = pd.read_csv(filename)\n",
    "num_trials = block_table['List_Reps'].loc[0]\n",
    "num_blocks = sum(~block_table['TP_LIST'].isna())\n",
    "\n",
    "tot_trials = int(sum(block_table['List_Reps']))\n",
    "filenames = np.empty((num_subjects, num_blocks,num_trials),dtype = object)\n",
    "reaction_trial_start = np.zeros((num_subjects, num_blocks,num_trials))*np.nan\n",
    "agent_reaction_leave_time = np.zeros((num_subjects, num_blocks,num_trials))*np.nan\n",
    "agent_reaction_decision_array = np.empty((num_subjects, num_blocks,num_trials))*np.nan\n",
    "\n",
    "reaction_trial_type_array = np.zeros((num_subjects, num_blocks,num_trials))*np.nan\n",
    "\n",
    "reaction_xypos_data = np.zeros((num_subjects, num_blocks,num_trials, trial_time,2))*np.nan\n",
    "reaction_dist_data = np.zeros((num_subjects, num_blocks,num_trials, trial_time))*np.nan\n",
    "reaction_xyvelocity_data = np.zeros((num_subjects, num_blocks,num_trials, trial_time,2))*np.nan\n",
    "reaction_speed_data = np.zeros((num_subjects, num_blocks,num_trials, trial_time))*np.nan\n",
    "    \n",
    "# reaction_xyforce_data = np.zeros((num_subjects, num_blocks,num_trials, trial_time,2))*np.nan\n",
    "# reaction_force_data = np.zeros((num_subjects, num_blocks,num_trials, trial_time))*np.nan\n",
    "\n",
    "coincidence_trial_time = 2500\n",
    "coincidence_trials = 50\n",
    "coincidence_trial_start = np.zeros((num_subjects, coincidence_trials))*np.nan\n",
    "coincidence_reach_time = np.zeros((num_subjects, coincidence_trials))*np.nan\n",
    "\n",
    "interval_trial_time = 2500\n",
    "interval_trials = 50\n",
    "interval_trial_start = np.zeros((num_subjects, interval_trials))*np.nan\n",
    "interval_reach_time =  np.zeros((num_subjects, interval_trials))*np.nan\n",
    "\n",
    "control_trials = interval_trials + coincidence_trials\n",
    "###-------------------------------------------------------------------------------------------------------\n",
    "for i in range(num_subjects):\n",
    "    if experiment == 'Exp2':\n",
    "        subname = analysis_pull_list_reaction[i]\n",
    "    else:\n",
    "        subname = analysis_pull_list_control[i]\n",
    "    print(i, subname)\n",
    "    trial_table = pd.read_csv(subname+f'\\\\{subname}Trial_Table.csv')\n",
    "    for x in range(tot_trials):\n",
    "        block_trial_num = trial_table.iloc[x]['Block_Step']\n",
    "        block_number = trial_table.iloc[x]['Block_Row']\n",
    "        tp_num = trial_table.iloc[x]['TP_Row']\n",
    "        j = tp_num - 1 # Block number\n",
    "        k = block_trial_num - 1 # Trial number in that block\n",
    "        \n",
    "        filename = f\"{subname}\\\\{task_name}_{subname}_C{block_number}_TP{tp_num}_T{block_trial_num}.csv\"\n",
    "        filenames[i,j,k] = filename # Store the file name\n",
    "        reaction_df = pd.read_csv(filename,engine='c',dtype={'Event_Codes': 'object'})  # Read in data\n",
    "        #* Find the trial start time with event codes\n",
    "        event_code_col = reaction_df['Event_Codes']\n",
    "        if experiment == 'Exp2':\n",
    "            if 'E_GO_TRIAL' in event_code_col.unique():\n",
    "                start_time = int(reaction_df[reaction_df['Event_Codes']=='E_GO_TRIAL'].index[-1]) #! Indexed at -1 bc if they need to redo the trial, we should use the last E_GO_TRIAL, not the first \n",
    "                reaction_trial_type_array[i,j,k] = 1 \n",
    "            elif 'E_SHUTOFF_TRIAL' in event_code_col.unique():\n",
    "                start_time = int(reaction_df[reaction_df['Event_Codes']=='E_SHUTOFF_TRIAL'].index[-1])\n",
    "                reaction_trial_type_array[i,j,k] = 0\n",
    "            else:\n",
    "                raise Exception('ERROR, event code not found')\n",
    "        else:\n",
    "            start_time = int(reaction_df[reaction_df['Event_Codes']=='E_SOUND_SIGNAL'].index[0])\n",
    "\n",
    "        #* Get Reaction Time Data\n",
    "        end_time = start_time + trial_time      # Find how long the trial is, constant in this case to give people time to make it\n",
    "        reaction_trial_start[i,j,k] = start_time         # Store the start times, NOT THE AGENT DECISION TIMES\n",
    "        if experiment == 'Exp2':\n",
    "            agent_reaction_leave_time[i,j,k] = reaction_df.iloc[start_time+1]['Agent_Decision_Time'] # Store the agent go time\n",
    "            agent_reaction_decision_array[i,j,k] = reaction_df.iloc[start_time+1]['Agent_Target_Selection']\n",
    "\n",
    "        cutoff_data = reaction_df.iloc[start_time:end_time] # Constrain data to the time that the trial starts, to the time that it ends\n",
    "            \n",
    "        reaction_xypos_data[i,j,k,:len(cutoff_data),:] = np.array(cutoff_data.drop(['Event_Codes'],axis=1)[['Left_HandX','Left_HandY']]) # Store left and right, slicing 3rd axis so if the trial ends early, then we just have nans at the end\n",
    "        lhx = cutoff_data['Left_HandX'].to_numpy() # Left hand x position\n",
    "        lhy = cutoff_data['Left_HandY'].to_numpy() # Left hand y position \n",
    "        lhx_vel = cutoff_data['Left_HandXVel'].to_numpy() # Left hand x velocity\n",
    "        lhy_vel = cutoff_data['Left_HandYVel'].to_numpy() # Left hand y velocity\n",
    "        # lhx_force = cutoff_data['Left_FS_ForceX'].to_numpy()\n",
    "        # lhy_force = cutoff_data['Left_FS_ForceY'].to_numpy()\n",
    "        \n",
    "        #* Filter force\n",
    "        # fx_nan_mask = ~np.isnan(lhx_force)\n",
    "        # fy_nan_mask = ~np.isnan(lhy_force)\n",
    "        # lhx_force_filt = np.zeros(trial_time)*np.nan\n",
    "        # lhy_force_filt = np.zeros(trial_time)*np.nan\n",
    "        # lhx_force_filt[:np.count_nonzero(fx_nan_mask)] = ff.Filter_KIN(lhx_force[fx_nan_mask])\n",
    "        # lhy_force_filt[:np.count_nonzero(fy_nan_mask)] = ff.Filter_KIN(lhy_force[fy_nan_mask])\n",
    "        # reaction_xyforce_data[i,j,k,:len(lhx_force_filt),0] = lhx_force_filt\n",
    "        # reaction_xyforce_data[i,j,k,:len(lhx_force_filt),1] = lhy_force_filt\n",
    "        # force = np.sqrt(lhx_force_filt**2 + lhy_force_filt**2)\n",
    "        # reaction_force_data[i,j,k,:] = force\n",
    "        \n",
    "        #* Filter velocity\n",
    "        vx_nan_mask = ~np.isnan(lhx_vel)\n",
    "        vy_nan_mask = ~np.isnan(lhy_vel)\n",
    "        lhx_vel_filt = np.zeros(trial_time)*np.nan\n",
    "        lhy_vel_filt = np.zeros(trial_time)*np.nan\n",
    "        lhx_vel_filt[:np.count_nonzero(vx_nan_mask)] = ff.Filter_KIN(lhx_vel[vx_nan_mask])\n",
    "        lhy_vel_filt[:np.count_nonzero(vy_nan_mask)] = ff.Filter_KIN(lhy_vel[vy_nan_mask])\n",
    "        \n",
    "        #* Get force, speed, dist and store them in arrays\n",
    "        reaction_xypos_data[i,j,k,:len(lhx),0] = lhx\n",
    "        reaction_xypos_data[i,j,k,:len(lhx),1] = lhy\n",
    "        dist = np.sqrt((lhx-startx)**2 + (lhy-starty)**2) # Calculate dist\n",
    "        reaction_dist_data[i,j,k,:len(dist)] = dist # Store dist\n",
    "        \n",
    "        left_target_dist = np.sqrt(np.sqrt((lhx-target1x)**2 + (lhy-target1y)**2)) # Calculate dist\n",
    "        reaction_dist_data[i,j,k,:len(dist)] = dist # Store dist\n",
    "        dist = np.sqrt((lhx-startx)**2 + (lhy-starty)**2) # Calculate dist\n",
    "        reaction_dist_data[i,j,k,:len(dist)] = dist # Store dist\n",
    "    \n",
    "        reaction_xyvelocity_data[i,j,k,:len(lhx_vel_filt),0] = lhx_vel_filt\n",
    "        reaction_xyvelocity_data[i,j,k,:len(lhx_vel_filt),1] = lhy_vel_filt\n",
    "        speed = np.sqrt((lhx_vel_filt)**2 + (lhy_vel_filt)**2) # Calculate velocity\n",
    "        reaction_speed_data[i,j,k,:len(speed)] = speed # Store velocity \n",
    "\n",
    "        # Get Interval Timing Data\n",
    "        if experiment == 'Exp1':\n",
    "            if tp_num == 1:\n",
    "                end_time = start_time + interval_trial_time\n",
    "                interval_trial_start[i,k] = start_time # Store start time\n",
    "                lhx = np.array(reaction_df.iloc[start_time:end_time]['Left_HandX'])\n",
    "                lhy = np.array(reaction_df.iloc[start_time:end_time]['Left_HandY'])\n",
    "                q = np.argwhere(np.sqrt((lhx-timing_targetx)**2 + (lhy-timing_targety)**2) < timing_target_radius) # THIS NEEDS TO BE THE CENTER TARGET... x poisition should be the start\n",
    "                if np.size(q)>0:\n",
    "                    interval_reach_time[i,k] = q[0]\n",
    "            # Get Coincidence Timing Data\n",
    "            if tp_num == 2:\n",
    "                end_time = start_time + coincidence_trial_time\n",
    "                coincidence_trial_start[i,k] = start_time # Store start time\n",
    "                lhx = np.array(reaction_df.iloc[start_time:end_time]['Left_HandX'])\n",
    "                lhy = np.array(reaction_df.iloc[start_time:end_time]['Left_HandY'])\n",
    "                q = np.argwhere(np.sqrt((lhx-timing_targetx)**2 + (lhy-timing_targety)**2) < timing_target_radius) # THIS NEEDS TO BE THE CENTER TARGET... x poisition should be the start\n",
    "                if np.size(q)>0:\n",
    "                    coincidence_reach_time[i,k] = q[0]\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Reaction Stuff (And timing for Exp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub20\n",
      "Subjects_Analyzed\\Sub20\\\n",
      "Sub23\n",
      "Subjects_Analyzed\\Sub23\\\n",
      "Sub24\n",
      "Subjects_Analyzed\\Sub24\\\n",
      "Sub25\n",
      "Subjects_Analyzed\\Sub25\\\n",
      "Sub26\n",
      "Subjects_Analyzed\\Sub26\\\n",
      "Sub27\n",
      "Subjects_Analyzed\\Sub27\\\n"
     ]
    }
   ],
   "source": [
    "if PICKLE:\n",
    "    i=-1\n",
    "    for subname in analysis_pull_list:\n",
    "        i+=1\n",
    "        data_path = f'Subjects_Analyzed\\\\{subname}\\\\'\n",
    "        if not os.path.exists(data_path):\n",
    "            os.makedirs(data_path)\n",
    "        print(subname)\n",
    "        print(data_path)\n",
    "        dill.dump(filenames[i,...], open(data_path + f'{subname}_filenames.pkl','wb'))                     \n",
    "        dill.dump(reaction_trial_start[i,...], open(data_path + f'{subname}_reaction_trial_start.pkl','wb'))                   \n",
    "        dill.dump(reaction_trial_type_array[i,...], open(data_path + f'{subname}_reaction_trial_type_array.pkl','wb'))                   \n",
    "        dill.dump(agent_reaction_leave_time[i,...], open(data_path + f'{subname}_agent_reaction_leave_time.pkl','wb'))  \n",
    "        dill.dump(agent_reaction_decision_array[i,...], open(data_path + f'{subname}_agent_reaction_decision_array.pkl','wb')) \n",
    "        dill.dump(reaction_trial_type_array[i,...], open(data_path + f'{subname}_trial_type_array.pkl','wb'))              \n",
    "        dill.dump(reaction_xypos_data[i,...], open(data_path + f'{subname}_reaction_xypos_data.pkl','wb'))           \n",
    "        dill.dump(reaction_dist_data[i,...], open(data_path + f'{subname}_reaction_dist_data.pkl','wb'))            \n",
    "        dill.dump(reaction_xyvelocity_data[i,...], open(data_path + f'{subname}_reaction_xyvelocity_data.pkl','wb'))      \n",
    "        dill.dump(reaction_speed_data[i,...], open(data_path + f'{subname}_reaction_speed_data.pkl','wb'))\n",
    "        if experiment == 'Exp1':\n",
    "            dill.dump(interval_trial_start[i,...], open(data_path + f'{subname}_interval_trial_start.pkl', 'wb'))\n",
    "            dill.dump(interval_reach_time[i,...], open(data_path + f'{subname}_interval_reach_time.pkl', 'wb'))\n",
    "            dill.dump(coincidence_trial_start[i,...], open(data_path + f'{subname}_coincidence_trial_start.pkl', 'wb'))\n",
    "            dill.dump(coincidence_reach_time[i,...], open(data_path + f'{subname}_coincidence_reach_time.pkl', 'wb'))\n",
    "        # dill.dump(reaction_xyforce_data[i,...], open(data_path + f'{subname}_reaction_xyforce_data.pkl','wb'))         \n",
    "        # dill.dump(reaction_force_data[i,...], open(data_path + f'{subname}_reaction_force_data.pkl','wb'))           "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Timing Data for Exp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Sub20_Timing\n",
      "1 Sub23_Timing\n",
      "2 Sub24_Timing\n",
      "3 Sub25_Timing\n",
      "4 Sub26_Timing\n",
      "5 Sub27_Timing\n"
     ]
    }
   ],
   "source": [
    "if experiment == 'Exp2':\n",
    "    coincidence_trial_time = 2500\n",
    "    coincidence_trials = 50\n",
    "    coincidence_trial_start = np.zeros((num_subjects, coincidence_trials))*np.nan\n",
    "    coincidence_reach_time = np.zeros((num_subjects, coincidence_trials))*np.nan\n",
    "\n",
    "    interval_trial_time = 2500\n",
    "    interval_trials = 50\n",
    "    interval_trial_start = np.zeros((num_subjects, interval_trials))*np.nan\n",
    "    interval_reach_time =  np.zeros((num_subjects, interval_trials))*np.nan\n",
    "\n",
    "    control_trials = interval_trials + coincidence_trials\n",
    "    ###-------------------------------------------------------------------------------------------------------\n",
    "    for i in range(num_subjects):\n",
    "        sub_name = analysis_pull_list_timing[i]\n",
    "        print(i, sub_name)\n",
    "        file = f'{sub_name}\\\\{sub_name}Trial_Table.csv'\n",
    "        control_trial_table = pd.read_csv(file)\n",
    "        block_number = 1\n",
    "        tp_num = 1\n",
    "        for x in ((range(control_trials))):\n",
    "            block_number = control_trial_table.iloc[x]['Block_Row']\n",
    "            tp_num = control_trial_table.iloc[x]['TP_Row']\n",
    "            block_trial_num = control_trial_table.iloc[x]['Block_Step']\n",
    "            filename = f'{sub_name}\\\\{task_name}_{sub_name}_C{block_number}_TP{tp_num}_T{block_trial_num}.csv'\n",
    "            j = tp_num - 1 # Block number\n",
    "            k = block_trial_num - 1 # Trial number in that block\n",
    "            data = pd.read_csv(filename, low_memory=False)\n",
    "            # if 'Agent_Initial_Time' in data.columns:\n",
    "            #     data = data.rename(columns = {'Agent_Inital_Time':'Agent_Decision_Time'}, inplace=True)\n",
    "            # f = data['Agent_Decision_Time']\n",
    "            start_time = int(data[data['Event_Codes']=='E_SOUND_SIGNAL'].index[0])\n",
    "            # Get Interval Timing Data\n",
    "            if tp_num == 1:\n",
    "                end_time = start_time + interval_trial_time\n",
    "                interval_trial_start[i,k] = start_time # Store start time\n",
    "                lhx = np.array(data.iloc[start_time:end_time]['Left_HandX'])\n",
    "                lhy = np.array(data.iloc[start_time:end_time]['Left_HandY'])\n",
    "                q = np.argwhere(np.sqrt((lhx-timing_targetx)**2 + (lhy-timing_targety)**2) < timing_target_radius) # THIS NEEDS TO BE THE CENTER TARGET... x poisition should be the start\n",
    "                if np.size(q)>0:\n",
    "                    interval_reach_time[i,k] = q[0]\n",
    "            # Get Coincidence Timing Data\n",
    "            if tp_num == 2:\n",
    "                end_time = start_time + coincidence_trial_time\n",
    "                coincidence_trial_start[i,k] = start_time # Store start time\n",
    "                lhx = np.array(data.iloc[start_time:end_time]['Left_HandX'])\n",
    "                lhy = np.array(data.iloc[start_time:end_time]['Left_HandY'])\n",
    "                q = np.argwhere(np.sqrt((lhx-timing_targetx)**2 + (lhy-timing_targety)**2) < timing_target_radius) # THIS NEEDS TO BE THE CENTER TARGET... x poisition should be the start\n",
    "                if np.size(q)>0:\n",
    "                    coincidence_reach_time[i,k] = q[0] \n",
    "                    \n",
    "                # #plot path for Reactions\n",
    "                if False:\n",
    "                    for i in range(1):\n",
    "                        player_reaction_time[0,0] = 500\n",
    "                        plot_end_time = int(start_time + player_reaction_time[i,k])\n",
    "                        # plot_end_time = int(start_time + 500)\n",
    "                        lhx_new = np.array(data.iloc[start_time:int(plot_end_time)]['Left_HandX'])\n",
    "                        lhy_new = np.array(data.iloc[start_time:int(plot_end_time)]['Left_HandY'])\n",
    "                        plt.figure(dpi=300)\n",
    "                        circleR = plt.Circle((target1x,target1y), target1_radius, color = 'r', fill = False)\n",
    "                        circleL = plt.Circle((target2x,target2y), target2_radius, color = 'r', fill = False)\n",
    "                        startCirc = plt.Circle((startx,starty), start_radius, color = 'r', fill = False)\n",
    "                        fig, ax = plt.subplots()\n",
    "                        ax.add_patch(circleR)\n",
    "                        ax.add_patch(circleL)\n",
    "                        ax.add_patch(startCirc)\n",
    "                        plt.plot(lhx_new,lhy_new) \n",
    "                        # plt.scatter(lhx_new[int(s[0])], lhy_new[int(s[0])])\n",
    "                        print(player_reaction_time[i,k])\n",
    "                        # plt.title(\"w =%1.0f \" %i + \"x=%1.0f \"%j + \"c=%1.0f\"%k + 'vely=%1.5f'%vel_check)\n",
    "                        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Timing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects_Analyzed\\Sub20\\\n",
      "Subjects_Analyzed\\Sub23\\\n",
      "Subjects_Analyzed\\Sub24\\\n",
      "Subjects_Analyzed\\Sub25\\\n",
      "Subjects_Analyzed\\Sub26\\\n",
      "Subjects_Analyzed\\Sub27\\\n"
     ]
    }
   ],
   "source": [
    "if experiment =='Exp2' and PICKLE:\n",
    "    i=-1\n",
    "    for subname in analysis_pull_list:\n",
    "        i+=1\n",
    "        data_path = f'Subjects_Analyzed\\\\{subname}\\\\'\n",
    "        if not os.path.exists(data_path):\n",
    "            os.makedirs(data_path)\n",
    "        print(data_path)\n",
    "        dill.dump(interval_trial_start[i,:], open(data_path + f'{subname}_interval_trial_start.pkl', 'wb'))\n",
    "        dill.dump(interval_reach_time[i,:], open(data_path + f'{subname}_interval_reach_time.pkl', 'wb'))\n",
    "        dill.dump(coincidence_trial_start[i,:], open(data_path + f'{subname}_coincidence_trial_start.pkl', 'wb'))\n",
    "        dill.dump(coincidence_reach_time[i,:], open(data_path + f'{subname}_coincidence_reach_time.pkl', 'wb'))\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Task Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Sub20_Task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:25<00:00, 12.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Sub23_Task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:14<00:00, 22.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Sub24_Task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:12<00:00, 26.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Sub25_Task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:11<00:00, 27.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Sub26_Task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:12<00:00, 26.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Sub27_Task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:12<00:00, 25.17it/s]\n"
     ]
    }
   ],
   "source": [
    "#%% Get task time task_df\n",
    "# Get trials, blocks, trial_time from trial_table\n",
    "path1 = PATH+'\\\\'+'Sub1_Task'\n",
    "task_df = pd.read_csv(path1+f'\\\\Sub1_TaskTrial_Table.csv')\n",
    "task_df = task_df.loc[task_df['Condition type']==3] # Only get the task condition \n",
    "num_trials = int(task_df.iloc[-1]['Block_Step']) # number of trials in each block\n",
    "if experiment == 'Exp2':\n",
    "    num_blocks = int(task_df.iloc[-1]['Block_Row'])\n",
    "else:\n",
    "    num_blocks = int(task_df.iloc[-1]['Block_Row']/2)\n",
    "    \n",
    "tot_trials = int(num_trials*num_blocks)\n",
    "trial_time = int(task_df.iloc[0]['Condition time']) + 500\n",
    "task_df_columns = len(fields_pull)\n",
    "# Need to be kept outside subject for-loop\n",
    "task_trial_start          = np.zeros((num_subjects, num_blocks, num_trials))*np.nan\n",
    "task_filenames            = np.empty((num_subjects, num_blocks,num_trials),dtype = object)\n",
    "agent_task_leave_time     = np.zeros((num_subjects, num_blocks,num_trials))*np.nan\n",
    "agent_task_decision_array = np.empty((num_subjects, num_blocks,num_trials))*np.nan\n",
    "task_xypos_data           = np.zeros((num_subjects, num_blocks,num_trials, trial_time,2))*np.nan\n",
    "task_dist_data            = np.zeros((num_subjects, num_blocks,num_trials, trial_time))*np.nan\n",
    "task_xyvelocity_data      = np.zeros((num_subjects, num_blocks,num_trials, trial_time,2))*np.nan\n",
    "task_speed_data           = np.zeros((num_subjects, num_blocks,num_trials, trial_time))*np.nan\n",
    "task_xyforce_data         = np.zeros((num_subjects, num_blocks,num_trials, trial_time,2))*np.nan\n",
    "task_force_data           = np.zeros((num_subjects, num_blocks,num_trials, trial_time))*np.nan\n",
    "\n",
    "###-------------------------------------------------------------------------------------------------------\n",
    "for i in range(num_subjects):\n",
    "    sub_name = analysis_pull_list_task[i]\n",
    "    print(i, sub_name)\n",
    "    path1 = PATH+'\\\\'+sub_name\n",
    "    file = path1+f'\\\\{sub_name}Trial_Table.csv'\n",
    "    trial_table = pd.read_csv(file)\n",
    "    # Splt trial table into task and washout based on condition type\n",
    "    if 'Condition_type' in trial_table:\n",
    "        task_trial_table = trial_table[trial_table['Condition_type']==3]\n",
    "    else:\n",
    "        task_trial_table = trial_table[trial_table['Condition type']==3]\n",
    "    \n",
    "    block_number = 1\n",
    "    tp_num = 1\n",
    "    for x in tqdm((range(tot_trials))):\n",
    "        block_number = task_trial_table.iloc[x]['Block_Row']\n",
    "        tp_num = task_trial_table.iloc[x]['TP_Row']\n",
    "        block_trial_num = task_trial_table.iloc[x]['Block_Step']\n",
    "        j = tp_num - task_trial_table['TP_Row'].min()  # Block number\n",
    "        k = block_trial_num - 1 # Trial number in that block\n",
    "        \n",
    "        filename = PATH+f\"\\\\{sub_name}\\\\{task_name}_{sub_name}_C{block_number}_TP{tp_num}_T{block_trial_num}.csv\"\n",
    "        task_filenames[i,j,k] = filename\n",
    "        task_df = pd.read_csv(filename, low_memory=False)\n",
    "        start_time = int(task_df[task_df['Event_Codes']=='E_SOUND_SIGNAL'].index[0])\n",
    "        task_trial_start[i,j,k] = start_time\n",
    "        end_time = start_time + trial_time\n",
    "        task_df = task_df.drop(columns ='Event_Codes') # Drop event codes cuz it's not number column and can't be an array \n",
    "        cutoff_data = task_df.iloc[start_time:end_time]\n",
    "        agent_task_decision_array[i,j,k] = task_df.iloc[start_time+1]['Agent_Target_Selection']\n",
    "        agent_task_leave_time[i,j,k] = task_df.iloc[start_time+1]['Agent_Decision_Time'] # Store the agent go time\n",
    "\n",
    "        \n",
    "        lhx = cutoff_data['Left_HandX'].to_numpy() # Left hand x position\n",
    "        lhy = cutoff_data['Left_HandY'].to_numpy() # Left hand y position \n",
    "        lhx_vel = cutoff_data['Left_HandXVel'].to_numpy() # Left hand x velocity\n",
    "        lhy_vel = cutoff_data['Left_HandYVel'].to_numpy() # Left hand y velocity\n",
    "        # lhx_force = cutoff_data['Left_FS_ForceX'].to_numpy()\n",
    "        # lhy_force = cutoff_data['Left_FS_ForceY'].to_numpy()\n",
    "        \n",
    "        # # Filter force\n",
    "        # fx_nan_mask = ~np.isnan(lhx_force)\n",
    "        # fy_nan_mask = ~np.isnan(lhy_force)\n",
    "        # lhx_force_filt = np.zeros(trial_time)*np.nan\n",
    "        # lhy_force_filt = np.zeros(trial_time)*np.nan\n",
    "        # lhx_force_filt[:np.count_nonzero(fx_nan_mask)] = ff.Filter_KIN(lhx_force[fx_nan_mask])\n",
    "        # lhy_force_filt[:np.count_nonzero(fy_nan_mask)] = ff.Filter_KIN(lhy_force[fy_nan_mask])\n",
    "        # Filter velocity\n",
    "        vx_nan_mask = ~np.isnan(lhx_vel)\n",
    "        vy_nan_mask = ~np.isnan(lhy_vel)\n",
    "        lhx_vel_filt = np.zeros(trial_time)*np.nan\n",
    "        lhy_vel_filt = np.zeros(trial_time)*np.nan\n",
    "        lhx_vel_filt[:np.count_nonzero(vx_nan_mask)] = ff.Filter_KIN(lhx_vel[vx_nan_mask])\n",
    "        lhy_vel_filt[:np.count_nonzero(vy_nan_mask)] = ff.Filter_KIN(lhy_vel[vy_nan_mask])\n",
    "        \n",
    "        #* Get force, speed, dist and store them in arrays\n",
    "        task_xypos_data[i,j,k,:len(lhx),0] = lhx\n",
    "        task_xypos_data[i,j,k,:len(lhx),1] = lhy\n",
    "        dist = np.sqrt((lhx-startx)**2 + (lhy-starty)**2) # Calculate dist\n",
    "        task_dist_data[i,j,k,:len(dist)] = dist # Store dist\n",
    "        \n",
    "        left_target_dist = np.sqrt(np.sqrt((lhx-target1x)**2 + (lhy-target1y)**2)) # Calculate dist\n",
    "        task_dist_data[i,j,k,:len(dist)] = dist # Store dist\n",
    "        dist = np.sqrt((lhx-startx)**2 + (lhy-starty)**2) # Calculate dist\n",
    "        task_dist_data[i,j,k,:len(dist)] = dist # Store dist\n",
    "        \n",
    "\n",
    "        # task_xyforce_data[i,j,k,:len(lhx_force_filt),0] = lhx_force_filt\n",
    "        # task_xyforce_data[i,j,k,:len(lhx_force_filt),1] = lhy_force_filt\n",
    "        # force = np.sqrt(lhx_force_filt**2 + lhy_force_filt**2)\n",
    "        # task_force_data[i,j,k,:] = force\n",
    "\n",
    "        task_xyvelocity_data[i,j,k,:len(lhx_vel_filt),0] = lhx_vel_filt\n",
    "        task_xyvelocity_data[i,j,k,:len(lhx_vel_filt),1] = lhy_vel_filt\n",
    "        speed = np.sqrt((lhx_vel_filt)**2 + (lhy_vel_filt)**2) # Calculate velocity\n",
    "        task_speed_data[i,j,k,:len(speed)] = speed # Store velocity \n",
    "           "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Task Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub20\n",
      "Sub23\n",
      "Sub24\n",
      "Sub25\n",
      "Sub26\n",
      "Sub27\n"
     ]
    }
   ],
   "source": [
    "if PICKLE:\n",
    "    i=-1\n",
    "    for subname in analysis_pull_list:\n",
    "        i+=1\n",
    "        data_path = PATH+f'\\\\Subjects_Analyzed\\\\{subname}\\\\'\n",
    "        if not os.path.exists(data_path):\n",
    "            os.makedirs(data_path)\n",
    "        print(subname)\n",
    "        dill.dump(task_trial_start[i,...], open(data_path + f'{subname}_task_trial_start.pkl','wb'))          \n",
    "        dill.dump(task_filenames[i,...], open(data_path + f'{subname}_task_filenames.pkl','wb'))            \n",
    "        dill.dump(agent_task_leave_time[i,...], open(data_path + f'{subname}_agent_task_leave_time.pkl','wb'))  \n",
    "        dill.dump(agent_task_decision_array[i,...], open(data_path + f'{subname}_agent_task_decision_array.pkl','wb')) \n",
    "        dill.dump(task_xypos_data[i,...], open(data_path + f'{subname}_task_xypos_data.pkl','wb'))           \n",
    "        dill.dump(task_dist_data[i,...], open(data_path + f'{subname}_task_dist_data.pkl','wb'))            \n",
    "        dill.dump(task_xyvelocity_data[i,...], open(data_path + f'{subname}_task_xyvelocity_data.pkl','wb'))      \n",
    "        dill.dump(task_speed_data[i,...], open(data_path + f'{subname}_task_speed_data.pkl','wb'))           \n",
    "        dill.dump(task_xyforce_data[i,...], open(data_path + f'{subname}_task_xyforce_data.pkl','wb'))         \n",
    "        dill.dump(task_force_data[i,...], open(data_path + f'{subname}_task_force_data.pkl','wb')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a00c1525417994d84940f6a64b96d4df953e4f0863c4f32c2c802abdf8195ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nv4 Uses the object imported from the py file class which is very similar to the Optimal_Stopping_Function_v3\\n\\nAs of 1/13/23, the only change is the addition of the decision to action delay\\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dill\n",
    "import importlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import data_visualization as dv\n",
    "import copy\n",
    "import numba as nb\n",
    "import time\n",
    "'''\n",
    "v4 Uses the object imported from the py file class which is very similar to the Optimal_Stopping_Function_v3\n",
    "\n",
    "As of 1/13/23, the only change is the addition of the decision to action delay\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Exp1 or Exp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"Exp1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_data_functions as rdf\n",
    "import plot_functions as pf\n",
    "import Optimal_Stopping_Object\n",
    "importlib.reload(Optimal_Stopping_Object)\n",
    "import Optimal_Stopping_Object as oso\n",
    "import Subject_Object_v2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Thangs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.use(\"cashaback_dark\")\n",
    "wheel = dv.ColorWheel()\n",
    "\n",
    "# Initial thangs\n",
    "os.chdir(f\"D:\\OneDrive - University of Delaware - o365\\Subject_Data\\MatchPennies_Agent_{experiment}\")\n",
    "PATH = os.getcwd()\n",
    "SAVE_PATH = f\"D:\\\\OneDrive - University of Delaware - o365\\\\Subject_Data\\\\MatchPennies_Agent_{experiment}\\\\Figures\\\\\"\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "\n",
    "# Fields pull and pull list\n",
    "figures_pull_list = []\n",
    "figures_pull_list_control = []\n",
    "figures_pull_list_task = []\n",
    "fields_pull = []\n",
    "with open(PATH + \"\\\\Figures_Pull_List.txt\", \"r\") as pull_file:\n",
    "    figures_pull_list = pull_file.read().splitlines()\n",
    "with open(PATH + \"\\\\Fields_Pull.txt\", \"r\") as fields_pull:\n",
    "    fields_pull = fields_pull.read().splitlines()\n",
    "num_subjects = len(figures_pull_list)\n",
    "if experiment == \"Exp2\":\n",
    "    tp3_title = \"Win = 1\\nIncorrect = 0\\nIndecision = 0\"\n",
    "    tp4_title = \"Win = 1\\nIncorrect = -1\\nIndecision = 0\"\n",
    "    tp5_title = \"Win = 1\\nIncorrect = 0\\nIndecision = -1\"\n",
    "    tp6_title = \"Win = 1\\nIncorrect = -1\\nIndecision = -1\"\n",
    "    trial_block_titles = [tp3_title, tp4_title, tp5_title, tp6_title]\n",
    "    num_blocks = len(trial_block_titles)\n",
    "    xlabel = \"Payoff Condition\"\n",
    "if experiment == \"Exp1\":\n",
    "    tp3_title = \"1000 (50)\"\n",
    "    tp4_title = \"1000 (150)\"\n",
    "    tp5_title = \"1100 (50)\"\n",
    "    tp6_title = \"1100 (150)\"\n",
    "    tp7_title = \"1200 (50)\"\n",
    "    tp8_title = \"1200 (150)\"\n",
    "    trial_block_titles = [tp3_title, tp4_title, tp5_title, tp6_title, tp7_title, tp8_title]\n",
    "    num_blocks = len(trial_block_titles)\n",
    "    xlabel = \"Mean [SD] Agent Decision Time (ms)\"\n",
    "num_subjects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"subject_objects\" not in locals():\n",
    "    subject_objects = rdf.generate_subject_objects(experiment)\n",
    "    subject_objects2 = copy.deepcopy(subject_objects)\n",
    "    # group = Subject_Object_v2.Group(subject_objects, select_trials = 'All Trials', num_stds_for_reaction_time = 2,\n",
    "    #                                     task_leave_time_metric_name = 'player_pos_task_leave_time', task_movement_time_metric_name = 'player_pos_task_movement_time',\n",
    "    #                                     reaction_time_metric_name = 'player_pos_reaction_time', reaction_movement_time_metric_name = 'player_pos_reaction_movement_time')\n",
    "    # group.analyze_data()\n",
    "    group = Subject_Object_v2.Group(\n",
    "        subject_objects2,\n",
    "        select_trials=\"All Trials\",\n",
    "        num_stds_for_reaction_time=2,\n",
    "        task_leave_time_metric_name=\"player_velocity_task_leave_time_thresh\",\n",
    "        task_movement_time_metric_name=\"player_velocity_task_movement_time_thresh\",\n",
    "        reaction_time_metric_name=\"player_velocity_reaction_time_thresh\",\n",
    "        reaction_movement_time_metric_name=\"player_velocity_reaction_movement_time_thresh\",\n",
    "    )\n",
    "    group.analyze_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run fit sequence for each individual  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment == \"Exp1\":\n",
    "    rt = np.nanmedian(group.reaction_time, axis=1) - 15\n",
    "    rt_sd = np.nanstd(group.reaction_time, axis=1)\n",
    "elif experiment == \"Exp2\":\n",
    "    rt    = np.nanmedian(group.react_reaction_time_only_react, axis=1) - 30\n",
    "    rt_sd = np.nanmedian(np.nanstd(group.reaction_time, axis=2))\n",
    "\n",
    "mt                   = np.min(np.nanmedian(group.player_task_movement_time, axis=2), axis=1)  # Get movement time for the condition where they tried the hardest\n",
    "mt_sd                = np.median(np.nanstd(group.player_task_movement_time, axis=2), axis=1)\n",
    "time_sd              = np.array([(np.nanstd(group.coincidence_reach_time, axis=1))] * num_blocks).T\n",
    "perc_wins_both_reach = group.perc_gamble_wins_when_both_decide\n",
    "gamble_sd            = np.nanstd(group.player_gamble_task_leave_time, axis=2)\n",
    "agent_sds            = np.nanstd(group.agent_task_leave_time, axis=2)\n",
    "agent_means          = np.nanmean(group.agent_task_leave_time, axis=2)\n",
    "\n",
    "model_expected_list = {}\n",
    "model_true_list = {}\n",
    "for i in range(1):\n",
    "    subname = figures_pull_list[i]\n",
    "    # model_expected = oso.ModelConstructor(\n",
    "    #     experiment=experiment,\n",
    "    #     num_blocks=num_blocks,\n",
    "    #     num_timesteps=1800,\n",
    "    #     BETA_ON=False,\n",
    "    #     agent_means=agent_means[i, :],\n",
    "    #     agent_sds=agent_sds[i, :],\n",
    "    #     reaction_time={\"true\": rt[i], \"exp\": rt[i]},\n",
    "    #     movement_time={\"true\": mt[i], \"exp\": mt[i]},\n",
    "    #     reaction_sd={\"true\": rt_sd[i], \"exp\": rt_sd[i]},\n",
    "    #     movement_sd={\"true\": mt_sd[i], \"exp\": mt_sd[i]},\n",
    "    #     timing_sd={\"true\": time_sd[i], \"exp\": time_sd[i]},\n",
    "    #     perc_wins_when_both_reach=perc_wins_both_reach[i],\n",
    "    #     gamble_delay_known=True,\n",
    "    #     gamble_sd_known=True,\n",
    "    #     gamble_decision_sd={\"true\": gamble_sd[i], \"exp\": 10},\n",
    "    #     gamble_delay={\"true\": 125, \"exp\": 50},\n",
    "    #     expected=True,\n",
    "    # )\n",
    "\n",
    "    model_true = oso.ModelConstructor(\n",
    "        experiment=experiment,\n",
    "        num_blocks=num_blocks,\n",
    "        num_timesteps=1800,\n",
    "        BETA_ON=False,\n",
    "        agent_means=agent_means[i, :],\n",
    "        agent_sds=agent_sds[i, :],\n",
    "        reaction_time={\"true\": rt[i], \"exp\": rt[i]},\n",
    "        movement_time={\"true\": mt[i], \"exp\": mt[i]},\n",
    "        reaction_sd={\"true\": rt_sd[i], \"exp\": rt_sd[i]},\n",
    "        movement_sd={\"true\": mt_sd[i], \"exp\": mt_sd[i]},\n",
    "        timing_sd={\"true\": time_sd[i], \"exp\": time_sd[i]},\n",
    "        perc_wins_when_both_reach=perc_wins_both_reach[i],\n",
    "        gamble_delay_known=True,\n",
    "        gamble_sd_known=True,\n",
    "        gamble_decision_sd={\"true\": gamble_sd[i], \"exp\": 10},\n",
    "        gamble_delay={\"true\": 125, \"exp\": 50},\n",
    "        expected=False,\n",
    "    )\n",
    "\n",
    "    # Fit true model\n",
    "    free_params_init = {'decision_time':np.array([900]*num_blocks),\n",
    "                        'reaction_time':np.array([model_true.inputs.reaction_time['true']]*num_blocks),\n",
    "                        }\n",
    "    # get_true_metric = model_true.results.get_metric\n",
    "    # init_decision_time = np.array([900]*num_blocks)\n",
    "    # init_model_leave_time = get_true_metric(model_true.player_behavior.wtd_leave_target_time, metric_type=\"optimal\")\n",
    "    # init_model_wins       = get_true_metric(model_true.score_metrics.prob_win, metric_type=\"optimal\")\n",
    "    # init_model_incorrects       = get_true_metric(model_true.score_metrics.prob_incorrect, metric_type=\"optimal\")\n",
    "    # init_model_indecisions       = get_true_metric(model_true.score_metrics.prob_indecision, metric_type=\"optimal\")\n",
    "\n",
    "    # init_model_metrics = np.array([init_decision_time,init_model_leave_time,init_model_wins,init_model_incorrects,init_model_indecisions])\n",
    "\n",
    "    targets = np.array(\n",
    "        [np.nanmedian(group.player_task_leave_time, axis=2)[i], \n",
    "        group.player_perc_wins[i], \n",
    "        group.player_perc_incorrects[i], \n",
    "        group.player_perc_indecisions[i]]\n",
    "    )\n",
    "    metric_keys = ['wtd_leave_target_time','prob_win','prob_incorrect','prob_indecision']\n",
    "    out = model_true.fit_multiple_parameters(\n",
    "            free_params_init=free_params_init,\n",
    "            targets=targets,\n",
    "            metric_keys=metric_keys,\n",
    "        )\n",
    "    # # Fit expected model\n",
    "    # model_expected.fit_model(\n",
    "    #     model_expected.player_behavior.wtd_leave_target_time,\n",
    "    #     np.nanmedian(group.player_task_leave_time, axis=2)[i],\n",
    "    # )\n",
    "    # Update dicts\n",
    "    model_true_list.update({subname: model_true})\n",
    "    # model_expected_list.update({subname: model_expected})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([882., 870., 968., 889., 960., 996.])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#TODO figure out this weirdness\n",
    "model_true.results.fit_decision_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[882.64860689, 871.        , 968.44622054, 889.3911642 ,\n",
       "        960.48615491, 996.47033484],\n",
       "       [216.64658187, 203.18088497, 213.17701128, 213.53576043,\n",
       "        192.69792708, 219.00677424]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aim1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

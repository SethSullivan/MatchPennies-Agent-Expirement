{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import dill\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import sys\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Subject_Object_v2' from 'D:\\\\OneDrive - University of Delaware - o365\\\\Desktop\\\\MatchPennies-Agent-Expirement\\\\Subject_Object_v2.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.insert(0,r'D:\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement')\n",
    "import Subject_Object_v2\n",
    "importlib.reload(Subject_Object_v2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'Exp1'\n",
    "if experiment == 'Exp1':\n",
    "    coincidence_trials = 50\n",
    "    interval_trials = 50\n",
    "    reaction_trials = 50\n",
    "    reaction_blocks = 1\n",
    "    trial_time = 5000\n",
    "    num_blocks = 6\n",
    "    num_trials = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Thangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields pull and pull list\n",
    "PATH = f'D:\\\\OneDrive - University of Delaware - o365\\\\Subject_Data\\\\MatchPennies_Agent_{experiment}'\n",
    "os.chdir(PATH)\n",
    "figures_pull_list = []\n",
    "fields_pull = []\n",
    "with open(PATH+\"\\\\Figures_Pull_List.txt\", \"r\") as pull_file:\n",
    "    figures_pull_list = pull_file.read().splitlines()\n",
    "with open(PATH+\"\\\\Fields_Pull.txt\", \"r\") as fields_pull:\n",
    "    fields_pull = fields_pull.read().splitlines()\n",
    "num_subjects = len(figures_pull_list)\n",
    "task_name = 'Agent_Shutoff_Go'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dill Load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dill Load Reaction and Timing Tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\OneDrive - University of Delaware - o365\\\\Subject_Data\\\\MatchPennies_Agent_Exp1\\\\Subjects_Analyzed\\\\Sub1\\\\Sub1_reaction_trial_type_array.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m data_path \u001b[39m=\u001b[39m PATH\u001b[39m+\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mSubjects_Analyzed\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m{\u001b[39;00msubname\u001b[39m}\u001b[39;00m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m     22\u001b[0m reaction_trial_start[i,\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]          \u001b[39m=\u001b[39m dill\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(data_path \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msubname\u001b[39m}\u001b[39;00m\u001b[39m_reaction_trial_start.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))          \n\u001b[1;32m---> 23\u001b[0m reaction_trial_type_array[i,\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]          \u001b[39m=\u001b[39m dill\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39;49m(data_path \u001b[39m+\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00msubname\u001b[39m}\u001b[39;49;00m\u001b[39m_reaction_trial_type_array.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m))          \n\u001b[0;32m     24\u001b[0m \u001b[39m# reaction_filenames[i,...]            = dill.load(open(data_path + f'{subname}_reaction_filenames.pkl','rb'))            \u001b[39;00m\n\u001b[0;32m     25\u001b[0m agent_reaction_leave_time[i,\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]     \u001b[39m=\u001b[39m dill\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(data_path \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msubname\u001b[39m}\u001b[39;00m\u001b[39m_agent_reaction_leave_time.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))  \n",
      "File \u001b[1;32mc:\\Users\\Seth Sullivan\\anaconda3\\envs\\py311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\OneDrive - University of Delaware - o365\\\\Subject_Data\\\\MatchPennies_Agent_Exp1\\\\Subjects_Analyzed\\\\Sub1\\\\Sub1_reaction_trial_type_array.pkl'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------Controls-------------------------\n",
    "reaction_trial_start          = np.zeros((num_subjects, reaction_blocks, reaction_trials))*np.nan\n",
    "reaction_filenames            = np.empty((num_subjects, reaction_blocks,reaction_trials),dtype = object)\n",
    "agent_reaction_leave_time     = np.zeros((num_subjects, reaction_blocks,reaction_trials))*np.nan\n",
    "agent_reaction_decision_array = np.empty((num_subjects, reaction_blocks,reaction_trials))*np.nan\n",
    "reaction_trial_type_array     = np.zeros((num_subjects, reaction_blocks,reaction_trials))*np.nan\n",
    "reaction_xypos_data           = np.zeros((num_subjects, reaction_blocks,reaction_trials, trial_time,2))*np.nan\n",
    "reaction_dist_data            = np.zeros((num_subjects, reaction_blocks,reaction_trials, trial_time))*np.nan\n",
    "reaction_xyvelocity_data      = np.zeros((num_subjects, reaction_blocks,reaction_trials, trial_time,2))*np.nan\n",
    "reaction_speed_data           = np.zeros((num_subjects, reaction_blocks,reaction_trials, trial_time))*np.nan\n",
    "reaction_xyforce_data         = np.zeros((num_subjects, reaction_blocks,reaction_trials, trial_time,2))*np.nan\n",
    "reaction_force_data           = np.zeros((num_subjects, reaction_blocks,reaction_trials, trial_time))*np.nan \n",
    "\n",
    "coincidence_trial_start                       = np.zeros((num_subjects, coincidence_trials))*np.nan\n",
    "coincidence_reach_time                        = np.zeros((num_subjects, coincidence_trials))*np.nan\n",
    "interval_trial_start                          = np.zeros((num_subjects, interval_trials))*np.nan\n",
    "interval_reach_time                           = np.zeros((num_subjects, interval_trials))*np.nan\n",
    "\n",
    "for i in range(num_subjects):\n",
    "    subname = figures_pull_list[i]\n",
    "    data_path = PATH+f'\\\\Subjects_Analyzed\\\\{subname}\\\\'\n",
    "    reaction_trial_start[i,...]          = dill.load(open(data_path + f'{subname}_reaction_trial_start.pkl','rb'))          \n",
    "    reaction_trial_type_array[i,...]          = dill.load(open(data_path + f'{subname}_reaction_trial_type_array.pkl','rb'))          \n",
    "    # reaction_filenames[i,...]            = dill.load(open(data_path + f'{subname}_reaction_filenames.pkl','rb'))            \n",
    "    agent_reaction_leave_time[i,...]     = dill.load(open(data_path + f'{subname}_agent_reaction_leave_time.pkl','rb'))  \n",
    "    agent_reaction_decision_array[i,...] = dill.load(open(data_path + f'{subname}_agent_reaction_decision_array.pkl','rb')) \n",
    "    reaction_xypos_data[i,...]           = dill.load(open(data_path + f'{subname}_reaction_xypos_data.pkl','rb'))           \n",
    "    reaction_dist_data[i,...]            = dill.load(open(data_path + f'{subname}_reaction_dist_data.pkl','rb'))            \n",
    "    reaction_xyvelocity_data[i,...]      = dill.load(open(data_path + f'{subname}_reaction_xyvelocity_data.pkl','rb'))      \n",
    "    reaction_speed_data[i,...]           = dill.load(open(data_path + f'{subname}_reaction_speed_data.pkl','rb'))           \n",
    "    reaction_xyforce_data[i,...]         = dill.load(open(data_path + f'{subname}_reaction_xyforce_data.pkl','rb'))         \n",
    "    reaction_force_data[i,...]           = dill.load(open(data_path + f'{subname}_reaction_force_data.pkl','rb')) \n",
    "    interval_trial_start[i,:]            = dill.load(open(data_path + f'{subname}_interval_trial_start.pkl', 'rb'))\n",
    "    interval_reach_time[i,:]             = dill.load(open(data_path + f'{subname}_interval_reach_time.pkl', 'rb'))\n",
    "    coincidence_trial_start[i,:]         = dill.load(open(data_path + f'{subname}_coincidence_trial_start.pkl', 'rb'))\n",
    "    coincidence_reach_time[i,:]          = dill.load(open(data_path + f'{subname}_coincidence_reach_time.pkl', 'rb'))\n",
    "    print(subname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dill Load Task and Washout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = PATH+'\\\\'+'Sub1_Task'\n",
    "task_df = pd.read_csv(path1+f'\\\\Sub1_TaskTrial_Table.csv')\n",
    "task_df = task_df.loc[task_df['Condition type']==3] # Only get the task condition \n",
    "num_trials = int(task_df.iloc[-1]['Block_Step']) # number of trials in each block\n",
    "num_blocks = int(task_df.iloc[-1]['Block_Row'])\n",
    "tot_trials = int(num_trials*num_blocks)\n",
    "trial_time = int(task_df.iloc[0]['Condition time'])\n",
    "task_df_columns = len(fields_pull)\n",
    "task_trials = 80\n",
    "task_blocks = 4\n",
    "trial_time = 2000\n",
    "# ---------------Controls-------------------------\n",
    "task_trial_start          = np.zeros((num_subjects, task_blocks, task_trials))*np.nan\n",
    "task_filenames            = np.empty((num_subjects, task_blocks,task_trials),dtype = object)\n",
    "agent_task_leave_time     = np.zeros((num_subjects, task_blocks,task_trials))*np.nan\n",
    "agent_task_decision_array = np.empty((num_subjects, task_blocks,task_trials))*np.nan\n",
    "task_xypos_data           = np.zeros((num_subjects, task_blocks,task_trials, trial_time,2))*np.nan\n",
    "task_dist_data            = np.zeros((num_subjects, task_blocks,task_trials, trial_time))*np.nan\n",
    "task_xyvelocity_data      = np.zeros((num_subjects, task_blocks,task_trials, trial_time,2))*np.nan\n",
    "task_speed_data           = np.zeros((num_subjects, task_blocks,task_trials, trial_time))*np.nan\n",
    "task_xyforce_data         = np.zeros((num_subjects, task_blocks,task_trials, trial_time,2))*np.nan\n",
    "task_force_data           = np.zeros((num_subjects, task_blocks,task_trials, trial_time))*np.nan \n",
    "\n",
    "for i in range(num_subjects):\n",
    "    subname = figures_pull_list[i]\n",
    "    data_path = PATH+f'\\\\Subjects_Analyzed\\\\{subname}\\\\'\n",
    "    task_trial_start[i,...]          = dill.load(open(data_path + f'{subname}_task_trial_start.pkl','rb'))          \n",
    "    # task_filenames[i,...]            = dill.load(open(data_path + f'{subname}_task_filenames.pkl','rb'))            \n",
    "    agent_task_leave_time[i,...]     = dill.load(open(data_path + f'{subname}_agent_task_leave_time.pkl','rb'))  \n",
    "    agent_task_decision_array[i,...] = dill.load(open(data_path + f'{subname}_agent_task_decision_array.pkl','rb')) \n",
    "    task_xypos_data[i,...]           = dill.load(open(data_path + f'{subname}_task_xypos_data.pkl','rb'))           \n",
    "    task_dist_data[i,...]            = dill.load(open(data_path + f'{subname}_task_dist_data.pkl','rb'))            \n",
    "    task_xyvelocity_data[i,...]      = dill.load(open(data_path + f'{subname}_task_xyvelocity_data.pkl','rb'))      \n",
    "    task_speed_data[i,...]           = dill.load(open(data_path + f'{subname}_task_speed_data.pkl','rb'))           \n",
    "    task_xyforce_data[i,...]         = dill.load(open(data_path + f'{subname}_task_xyforce_data.pkl','rb'))         \n",
    "    task_force_data[i,...]           = dill.load(open(data_path + f'{subname}_task_force_data.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Subject Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub1\n",
      "Sub2\n",
      "Sub4\n",
      "Sub5\n",
      "Sub6\n",
      "Sub7\n",
      "Sub8\n",
      "Sub9\n",
      "Sub10\n",
      "Sub11\n",
      "Sub12\n"
     ]
    }
   ],
   "source": [
    "path1 = PATH+'\\\\'+'Sub1_Task'\n",
    "task_df = pd.read_csv(path1+f'\\\\Sub1_TaskTrial_Table.csv')\n",
    "task_df = task_df.loc[task_df['Condition type']==3] # Only get the task condition \n",
    "num_trials = int(task_df.iloc[-1]['Block_Step']) # number of trials in each block\n",
    "num_blocks = int(task_df.iloc[-1]['Block_Row'])\n",
    "tot_trials = int(num_trials*num_blocks)\n",
    "trial_time = int(task_df.iloc[0]['Condition time'])\n",
    "task_df_columns = len(fields_pull)\n",
    "trial_table = np.empty((num_subjects, tot_trials, 4), int)\n",
    "\n",
    "data_path = 'Subjects_Analyzed\\\\'\n",
    "subject_objects = []\n",
    "for i in range(num_subjects):\n",
    "    subname = figures_pull_list[i]\n",
    "    print(subname)\n",
    "    subject_object = Subject_Object_v2.Subject(\n",
    "        experiment = 'Exp2', num_task_trials_initial = 80, num_task_blocks = 4, num_reaction_blocks = 3, num_reaction_trials = 100,num_timing_trials = 50,\n",
    "\n",
    "        reaction_xypos_data = reaction_xypos_data[i],reaction_dist_data = reaction_dist_data[i],\n",
    "        reaction_xyvelocity_data = reaction_xyvelocity_data[i],reaction_speed_data = reaction_speed_data[i],reaction_trial_type_array = reaction_trial_type_array[i], agent_reaction_decision_array = agent_reaction_decision_array[i],\n",
    "        agent_reaction_leave_time = agent_reaction_leave_time[i], \n",
    "        \n",
    "        task_xypos_data = task_xypos_data[i], task_dist_data = task_dist_data[i], task_xyvelocity_data = task_xyvelocity_data[i], task_speed_data = task_speed_data[i],\n",
    "        interval_trial_start = interval_trial_start[i], interval_reach_time = interval_reach_time[i], coincidence_trial_start = coincidence_trial_start[i], coincidence_reach_time = coincidence_reach_time[i],\n",
    "        agent_task_leave_time = agent_task_leave_time[i], agent_task_decision_array = agent_task_decision_array[i],\n",
    "                                )\n",
    "    subject_objects.append(subject_object)\n",
    "    dill.dump(subject_object, open(data_path + f'{subname}\\\\{subname}_object.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a00c1525417994d84940f6a64b96d4df953e4f0863c4f32c2c802abdf8195ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "import random\n",
    "import numba as nb\n",
    "from numba.experimental import jitclass\n",
    "from numba import types,typed, typeof\n",
    "from numba import int32, float32    # import the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimal_Decision_Time_Simulation():\n",
    "    def __init__(self,**kwargs):\n",
    "        self.TRIAL_TIME = kwargs.get('TRIAL_TIME',1500)\n",
    "        self.NUM_TRIALS = kwargs.get('NUM_TRIALS',10000)\n",
    "        self.AGENT_MOVEMENT_TIME = kwargs.get('AGENT_MOVEMENT_TIME',150)\n",
    "        # Inputs to draw random decision times (THIS USES TIMING UNCERTAINTY)\n",
    "        self.interval = kwargs.get('interval',25)\n",
    "        self.agent_start_mean = kwargs.get('agent_start_mean',900)\n",
    "        self.agent_end_mean = kwargs.get('agent_end_mean',1550)\n",
    "        self.player_start_mean = kwargs.get('player_start_mean',900)\n",
    "        self.player_end_mean = kwargs.get('player_end_mean',1550)\n",
    "        self.agent_decision_means = np.arange(self.agent_start_mean,self.agent_end_mean,self.interval)\n",
    "        self.player_decision_means = np.arange(self.player_start_mean,self.player_end_mean,self.interval)\n",
    "        self.m = len(self.player_decision_means)\n",
    "        self.n = len(self.agent_decision_means)\n",
    "        \n",
    "        \n",
    "        self.reaction_time_mean = kwargs.get('reaction_time_mean')\n",
    "        self.movement_time_mean = kwargs.get('movement_time_mean')\n",
    "        self.timing_uncertainty = kwargs.get('timing_uncertainty')\n",
    "        self.reaction_uncertainty = kwargs.get('reaction_uncertainty')\n",
    "        self.movement_uncertainty = kwargs.get('movement_uncertainty')\n",
    "        self.agent_uncertainty = kwargs.get('agent_uncertainty') \n",
    " \n",
    "        # Random variables inputs\n",
    "        self.draw_times()\n",
    "        print(type(self.reaction_time_mean))\n",
    "        print(type(self.m))\n",
    "        print(type(self.agent_decision_means))\n",
    "        \n",
    "    def draw_times(self):\n",
    "        self.player_decision_times = np.zeros((self.m,self.n,self.NUM_TRIALS))\n",
    "        self.reaction_times = np.zeros((self.m,self.n,self.NUM_TRIALS))\n",
    "        self.movement_times = np.zeros((self.m,self.n,self.NUM_TRIALS))\n",
    "        self.agent_decision_times = np.zeros((self.m,self.n,self.NUM_TRIALS))\n",
    "        for i in range(self.m):\n",
    "            for j in range(self.n):\n",
    "                self.player_decision_times[i,j,:] = stats.norm.rvs(self.player_decision_means[i],self.timing_uncertainty,size = self.NUM_TRIALS)\n",
    "                self.reaction_times[i,j,:] = stats.norm.rvs(self.reaction_time_mean,self.reaction_uncertainty,size=self.NUM_TRIALS)\n",
    "                self.movement_times[i,j,:] = stats.norm.rvs(self.movement_time_mean,self.movement_uncertainty,size=self.NUM_TRIALS)\n",
    "                self.agent_decision_times[i,j,:] = stats.norm.rvs(self.agent_decision_means[j],self.agent_uncertainty,size = self.NUM_TRIALS)\n",
    "    def simulation(self):\n",
    "        if True: # Initialize arrays\n",
    "            self.player_wins = np.zeros((self.m, self.n))\n",
    "            self.player_reaction_wins = np.zeros((self.m, self.n))\n",
    "            self.player_gamble_wins = np.zeros((self.m, self.n))\n",
    "            \n",
    "            self.player_incorrects = np.zeros((self.m, self.n))\n",
    "            self.player_reaction_incorrects = np.zeros((self.m, self.n))\n",
    "            self.player_gamble_incorrects = np.zeros((self.m, self.n))\n",
    "            \n",
    "            self.player_indecisions = np.zeros((self.m, self.n))\n",
    "            self.player_reaction_indecisions = np.zeros((self.m, self.n))\n",
    "            self.player_gamble_indecisions = np.zeros((self.m, self.n))\n",
    "            \n",
    "            self.player_decision_array = np.empty((self.m, self.n, self.NUM_TRIALS)) #0 is indecision, 1 is win, -1 is loss\n",
    "            self.agent_decision_array = np.empty((self.m, self.n, self.NUM_TRIALS))\n",
    "            \n",
    "            self.player_reach_times = np.empty((self.m, self.n, self.NUM_TRIALS))\n",
    "            self.player_leave_target_times = np.empty((self.m, self.n, self.NUM_TRIALS))\n",
    "            self.agent_reach_times = np.empty((self.m, self.n, self.NUM_TRIALS))\n",
    "        for i in range(self.m):\n",
    "            for j in range(self.n):\n",
    "                for k in range(self.NUM_TRIALS):\n",
    "                     # For gambles, reach time is decision time + movement time.. this get's overwritten for reaction if statement\n",
    "                     # LEave target time is player decision time for gambles, again get's changed in first if statement\n",
    "                    self.player_leave_target_times[i,j,k] = self.player_decision_times[i,j,k]\n",
    "                    self.player_reach_times[i,j,k] = self.player_decision_times[i,j,k] + self.movement_times[i,j,k]\n",
    "                    self.agent_reach_times[i,j,k] = self.agent_decision_times[i,j,k] + self.AGENT_MOVEMENT_TIME\n",
    "                    \n",
    "                    if ((self.player_decision_times[i,j,k] >= self.agent_decision_times[i,j,k])): # If player selects after agent, they are forced to react\n",
    "                        self.player_leave_target_times[i,j,k] = self.agent_decision_times[i,j,k] + self.reaction_times[i,j,k] # PLayer can immediately react to the agent\n",
    "                        self.player_reach_times[i,j,k] = self.player_leave_target_times[i,j,k] + self.movement_times[i,j,k]\n",
    "                        if self.player_reach_times[i,j,k] > self.TRIAL_TIME:\n",
    "                            self.player_wins[i,j] += 1\n",
    "                            self.player_reaction_wins[i,j] += 1\n",
    "                            self.player_decision_array[i,j,k] = 1\n",
    "                            self.agent_decision_array[i,j,k] = -1\n",
    "                            \n",
    "                        else: # Player doesn't make it\n",
    "                            self.player_indecisions[i,j]+=1\n",
    "                            self.player_reaction_indecisions[i,j]+=1\n",
    "                            self.player_decision_array[i,j,k] = 0\n",
    "                            self.agent_decision_array[i,j,k] = 1\n",
    "                            if self.agent_decision_times[i,j,k] + self.AGENT_MOVEMENT_TIME > self.TRIAL_TIME: # Agent doesn't make it either\n",
    "                                self.agent_decision_array[i,j,k] = 0\n",
    "                    # NO sensory evidence was used---------------------------------\n",
    "                    # Both made it\n",
    "                    elif(self.player_reach_times[i,j,k] < self.TRIAL_TIME and \n",
    "                         self.agent_reach_times[i,j,k] < self.TRIAL_TIME):\n",
    "                        rand = random.random()\n",
    "                        \n",
    "                        if rand>=0.5:\n",
    "                            self.player_wins[i,j] += 1\n",
    "                            self.player_gamble_wins[i,j] += 1\n",
    "                            self.player_decision_array[i,j,k] = 1\n",
    "                            self.agent_decision_array[i,j,k] = -1\n",
    "                        if rand<0.5:\n",
    "                            self.player_incorrects[i,j] += 1\n",
    "                            self.player_gamble_incorrects[i,j] += 1\n",
    "                            self.player_decision_array[i,j,k] = -1\n",
    "                            self.agent_decision_array[i,j,k] = 1\n",
    "                    # Player didn't make it, agent did\n",
    "                    elif(self.player_reach_times[i,j,k]>=self.TRIAL_TIME and \n",
    "                         self.agent_reach_times[i,j,k]<self.TRIAL_TIME):\n",
    "                        self.player_indecisions[i,j] += 1\n",
    "                        self.player_gamble_indecisions[i,j]+=1\n",
    "                        self.player_decision_array[i,j,k] = 0\n",
    "                        self.agent_decision_array[i,j,k] = 1\n",
    "                    # Agent didn't make it, player did\n",
    "                    elif(self.player_reach_times[i,j,k]<self.TRIAL_TIME and \n",
    "                         self.agent_reach_times[i,j,k]>=self.TRIAL_TIME):\n",
    "                        self.player_wins[i,j] += 1\n",
    "                        self.player_gamble_wins[i,j]+=1\n",
    "                        self.player_decision_array[i,j,k] = 1\n",
    "                        self.agent_decision_array[i,j,k] = 0\n",
    "                    # Both didn't make it\n",
    "                    elif(self.player_reach_times[i,j,k]>self.TRIAL_TIME and \n",
    "                         self.agent_reach_times[i,j,k]>self.TRIAL_TIME):\n",
    "                        self.player_indecisions[i,j] += 1\n",
    "                        self.player_gamble_indecisions[i,j]+=1\n",
    "                        self.player_decision_array[i,j,k] = 0\n",
    "                        self.agent_decision_array[i,j,k] = 0\n",
    "                    else:\n",
    "                        print('ERROR NO IF STATEMENT TRIGGERED')\n",
    "                            \n",
    "                        \n",
    "                    \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Initialize what I want to return\n",
    "sim = Optimal_Decision_Time_Simulation(reaction_time_mean = 325, movement_time_mean = 90, timing_uncertainty=100, reaction_uncertainty = 30, movement_uncertainty = 30,agent_uncertainty = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121240"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.logical_and(sim.player_decision_array==0,sim.agent_decision_array==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1698363"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.logical_and(sim.player_decision_times > sim.agent_decision_times,\n",
    "                                sim.agent_decision_times+sim.movement_times+sim.reaction_times < sim.TRIAL_TIME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1681056.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sim.player_reaction_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.TRIAL_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a00c1525417994d84940f6a64b96d4df953e4f0863c4f32c2c802abdf8195ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

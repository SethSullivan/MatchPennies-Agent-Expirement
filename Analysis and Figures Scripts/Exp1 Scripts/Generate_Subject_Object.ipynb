{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import dill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Subject_Object import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Thangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\Subject_Data\\\\Seth_MatchPennies_Agent_Exp1\\\\')\n",
    "PATH = os.getcwd()\n",
    "# Fields pull and pull list\n",
    "os.chdir('D:\\Subject_Data\\Seth_MatchPennies_Agent_Exp1')\n",
    "PATH = os.getcwd()\n",
    "figures_pull_list = []\n",
    "fields_pull = []\n",
    "with open(PATH+\"\\\\Figures_Pull_List.txt\", \"r\") as pull_file:\n",
    "    figures_pull_list = pull_file.read().splitlines()\n",
    "with open(PATH+\"\\\\Fields_Pull.txt\", \"r\") as fields_pull:\n",
    "    fields_pull = fields_pull.read().splitlines()\n",
    "NUM_SUBJECTS = len(figures_pull_list)\n",
    "task_name = 'Seth_MatchPennies_Agent_Exp1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dill Load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dill Load Control Tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coincidence_trials = 50\n",
    "reaction_trials = 50\n",
    "interval_trials = 50\n",
    "# ---------------Controls-------------------------\n",
    "player_reaction_decision_array = np.empty((NUM_SUBJECTS, reaction_trials))\n",
    "agent_reaction_decision_array = np.empty((NUM_SUBJECTS, reaction_trials))\n",
    "player_reaction_time = np.zeros([NUM_SUBJECTS,reaction_trials])*np.nan \n",
    "player_reaction_movement_time = np.zeros([NUM_SUBJECTS,reaction_trials])*np.nan\n",
    "reaction_trial_start = np.zeros((NUM_SUBJECTS,reaction_trials))*np.nan \n",
    "coincidence_trial_start = np.zeros((NUM_SUBJECTS, coincidence_trials))*np.nan\n",
    "coincidence_reach_time = np.zeros((NUM_SUBJECTS, coincidence_trials))*np.nan\n",
    "interval_trial_start = np.zeros((NUM_SUBJECTS, interval_trials))*np.nan\n",
    "interval_reach_time = np.zeros((NUM_SUBJECTS, interval_trials))*np.nan\n",
    "\n",
    "for i in range(NUM_SUBJECTS):\n",
    "    subname = figures_pull_list[i]\n",
    "    data_path = PATH+f'\\\\Subjects_Analyzed\\\\{subname}\\\\'\n",
    "    reaction_trial_start[i,:] = dill.load(open(data_path + f'{subname}_reaction_trial_start.pkl', 'rb'))\n",
    "    player_reaction_time[i,:] = dill.load(open(data_path + f'{subname}_player_reaction_time.pkl', 'rb'))\n",
    "    player_reaction_movement_time[i,:] = dill.load(open(data_path + f'{subname}_player_reaction_movement_time.pkl', 'rb'))\n",
    "    player_reaction_decision_array[i,:] = dill.load(open(data_path + f'{subname}_player_reaction_decision_array.pkl', 'rb'))\n",
    "    agent_reaction_decision_array[i,:] = dill.load(open(data_path + f'{subname}_agent_reaction_decision_time.pkl', 'rb'))\n",
    "    reaction_trial_start[i,:] = dill.load(open(data_path + f'{subname}_reaction_trial_start.pkl', 'rb'))\n",
    "    interval_trial_start[i,:] = dill.load(open(data_path + f'{subname}_interval_trial_start.pkl', 'rb'))\n",
    "    interval_reach_time[i,:] = dill.load(open(data_path + f'{subname}_interval_reach_time.pkl', 'rb'))\n",
    "    coincidence_trial_start[i,:] = dill.load(open(data_path + f'{subname}_coincidence_trial_start.pkl', 'rb'))\n",
    "    coincidence_reach_time[i,:] =  dill.load(open(data_path + f'{subname}_coincidence_reach_time.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dill Load Task and Washout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = PATH+'\\\\'+'Sub1_Task'\n",
    "task_df = pd.read_csv(path1+f'\\\\Sub1_TaskTrial_Table.csv')\n",
    "task_df = task_df.loc[task_df['Condition type']==3] # Only get the task condition \n",
    "num_trials = int(task_df.iloc[-1]['Block_Step']) # number of trials in each block\n",
    "num_blocks = int(task_df.iloc[-1]['Block_Row']/2)\n",
    "tot_trials = int(num_trials*num_blocks)\n",
    "trial_time = int(task_df.iloc[0]['Condition time'])\n",
    "task_df_columns = len(fields_pull)\n",
    "trial_table = np.empty((NUM_SUBJECTS, tot_trials, 4), int)\n",
    "#----------------- TASK--------------------------------\n",
    "player_task_reach_time = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan \n",
    "player_task_decision_time = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan \n",
    "player_task_decision_array = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan\n",
    "player_task_movement_time = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan\n",
    "agent_task_reach_time = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan \n",
    "agent_task_decision_time = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan \n",
    "agent_task_decision_array = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan\n",
    "\n",
    "# -------------- Washout-------------------\n",
    "washout_trials = 25\n",
    "player_washout_reach_time = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan \n",
    "player_washout_decision_time = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan \n",
    "player_washout_decision_array = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan\n",
    "player_washout_movement_time = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan\n",
    "agent_washout_reach_time = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan \n",
    "agent_washout_decision_time = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan \n",
    "agent_washout_decision_array = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan\n",
    "agent_washout_movement_time = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan\n",
    "\n",
    "for i in range(NUM_SUBJECTS):\n",
    "    subname = figures_pull_list[i]\n",
    "    data_path = PATH+f'\\\\Subjects_Analyzed\\\\{subname}\\\\'\n",
    "    #task_data[i,:,:,:,:] = dill.load(open(data_path + f'{subname}_task_data.pkl', 'rb'))\n",
    "    player_task_decision_time[i,:,:] = dill.load( open(data_path + f'{subname}_player_task_decision_time.pkl', 'rb'))\n",
    "    player_task_decision_array[i,:,:] = dill.load( open(data_path + f'{subname}_player_task_decision_array.pkl', 'rb'))\n",
    "    player_task_movement_time[i,:,:] = dill.load(open(data_path + f'{subname}_player_task_movement_time.pkl', 'rb'))\n",
    "    player_task_reach_time[i,:,:] = dill.load( open(data_path + f'{subname}_player_task_reach_time.pkl', 'rb'))\n",
    "    agent_task_decision_time[i,:,:] = dill.load( open(data_path + f'{subname}_agent_task_decision_time.pkl', 'rb'))\n",
    "    agent_task_decision_array[i,:,:] = dill.load(open(data_path + f'{subname}_agent_task_decision_array.pkl', 'rb'))\n",
    "    agent_task_reach_time[i,:,:] = agent_task_decision_time[i,:,:] + 150\n",
    "    player_washout_decision_time[i,:,:] = dill.load( open(data_path + f'{subname}_player_washout_decision_time.pkl', 'rb'))\n",
    "    player_washout_decision_array[i,:,:] = dill.load( open(data_path + f'{subname}_player_washout_decision_array.pkl', 'rb'))\n",
    "    player_washout_movement_time[i,:,:] = dill.load(open(data_path + f'{subname}_player_washout_movement_time.pkl', 'rb'))\n",
    "    player_washout_reach_time[i,:,:] = dill.load( open(data_path + f'{subname}_player_washout_reach_time.pkl', 'rb'))\n",
    "    agent_washout_decision_time[i,:,:] = dill.load( open(data_path + f'{subname}_agent_washout_decision_time.pkl', 'rb'))\n",
    "    agent_washout_decision_array[i,:,:] = dill.load(open(data_path + f'{subname}_agent_washout_decision_array.pkl', 'rb'))\n",
    "    agent_washout_reach_time[i,:,:] = dill.load(open(data_path + f'{subname}_agent_washout_reach_time.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Subject Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub1\n",
      "Sub2\n",
      "Sub3\n",
      "Sub4\n",
      "Sub5\n",
      "Sub6\n",
      "Sub7\n",
      "Sub8\n",
      "Sub9\n",
      "Sub10\n",
      "Sub11\n",
      "Sub12\n",
      "Sub13\n",
      "Sub14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:206: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.perc_reaction_wins = (self.reaction_wins/self.total_reactions)*100 # Array division\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:207: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.perc_reaction_incorrects = (self.reaction_incorrects/self.total_reactions)*100\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:208: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.perc_reaction_indecisions = (self.reaction_indecisions/self.total_reactions)*100\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:225: RuntimeWarning: Mean of empty slice\n",
      "  self.reaction_decision_time_means = np.nanmean(self.reaction_decision_time, axis = 1 )\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:227: RuntimeWarning: Mean of empty slice\n",
      "  self.agent_task_decision_time_reaction_means = np.nanmean(self.agent_task_decision_time_reactions, axis = 1)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.perc_binned_player_wins = (self.binned_player_wins/self.bin_length_each_condition)*100\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:294: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.perc_binned_player_indecisions = (self.binned_player_indecisions/self.bin_length_each_condition)*100\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:295: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.perc_binned_player_incorrects = (self.binned_player_incorrects/self.bin_length_each_condition)*100\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:297: RuntimeWarning: Mean of empty slice\n",
      "  self.binned_player_task_decision_times_mean = np.nanmean(self.binned_player_task_decision_times,axis=2) # Mean for each bin, each condition\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:298: RuntimeWarning: Mean of empty slice\n",
      "  self.binned_player_minus_agent_task_decision_time_mean = np.nanmean(self.binned_player_minus_agent_task_decision_time,axis=2)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:217: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.perc_incorrects_that_were_gambles = (self.gamble_incorrects/self.player_incorrects)*100\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.perc_incorrects_that_were_reactions = (self.reaction_incorrects/self.player_incorrects)*100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:358: RuntimeWarning: Mean of empty slice\n",
      "  self.perc_binned_player_wins_mean = np.nanmean(self.combine_all_subjects('perc_binned_player_wins'),axis = 0)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:359: RuntimeWarning: Mean of empty slice\n",
      "  self.perc_binned_player_indecisions_mean = np.nanmean(self.combine_all_subjects('perc_binned_player_indecisions'),axis = 0)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:360: RuntimeWarning: Mean of empty slice\n",
      "  self.perc_binned_player_incorrects_mean = np.nanmean(self.combine_all_subjects('perc_binned_player_incorrects'),axis = 0)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:361: RuntimeWarning: Mean of empty slice\n",
      "  self.binned_player_minus_agent_task_decision_time_mean = np.nanmean(self.combine_all_subjects('binned_player_minus_agent_task_decision_time_mean'),axis = 0)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Analysis and Figures Scripts\\Exp1 Scripts\\Subject_Object.py:362: RuntimeWarning: Mean of empty slice\n",
      "  self.binned_player_task_decision_times_mean = np.nanmean(self.combine_all_subjects('binned_player_task_decision_times_mean'),axis = 0)\n"
     ]
    }
   ],
   "source": [
    "NUM_STDS_FOR_REACTION_TIME = 1\n",
    "data_path = 'D:\\\\Subject_Data\\\\Seth_MatchPennies_Agent_Exp1\\\\Subjects_Analyzed\\\\'\n",
    "subject_object_dict = {}\n",
    "for i in range(NUM_SUBJECTS):\n",
    "    subname = figures_pull_list[i]\n",
    "    print(subname)\n",
    "    subject_object_dict.update({subname: Subject(num_trials = 80, num_blocks = 6, num_control_trials = 50, num_washout_trials = 25, reaction_time = player_reaction_time[i], reaction_movement_time = player_reaction_movement_time[i],\n",
    "                                interval_trial_start = interval_trial_start[i], interval_reach_time = interval_reach_time[i], coincidence_trial_start = coincidence_trial_start[i], coincidence_reach_time = coincidence_reach_time[i],\n",
    "                                player_task_reach_time = player_task_reach_time[i], player_task_decision_time = player_task_decision_time[i], player_task_decision_array = player_task_decision_array[i],\n",
    "                                player_task_movement_time = player_task_movement_time[i], agent_task_reach_time = agent_task_reach_time[i], agent_task_decision_time = agent_task_decision_time[i], agent_task_decision_array = agent_task_decision_array[i],\n",
    "                                player_washout_reach_time = player_washout_reach_time[i], player_washout_decision_time = player_washout_decision_time[i], player_washout_decision_array = player_washout_decision_array[i],\n",
    "                                player_washout_movement_time = player_washout_movement_time[i], agent_washout_reach_time = agent_washout_reach_time[i], agent_washout_decision_time = agent_washout_decision_time[i], agent_washout_decision_array = agent_washout_decision_array[i],\n",
    "                                num_stds_for_reaction_time = NUM_STDS_FOR_REACTION_TIME\n",
    "                                )}\n",
    "                               )\n",
    "    dill.dump(subject_object_dict[subname], open(data_path + f'{subname}\\\\{subname}_object.pkl', 'wb'))\n",
    "dill.dump(subject_object_dict,open(data_path + 'subject_object_dict.pkl', 'wb'))\n",
    "\n",
    "group = Group(list(subject_object_dict.values()))\n",
    "dill.dump(group,open(data_path + 'group_object.pkl','wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a00c1525417994d84940f6a64b96d4df953e4f0863c4f32c2c802abdf8195ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

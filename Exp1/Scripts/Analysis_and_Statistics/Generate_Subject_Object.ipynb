{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import dill\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Subject_Object\n",
    "importlib.reload(Subject_Object)\n",
    "from Subject_Object import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Thangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\Subject_Data\\\\Seth_MatchPennies_Agent_Exp1\\\\')\n",
    "PATH = os.getcwd()\n",
    "# Fields pull and pull list\n",
    "os.chdir('D:\\Subject_Data\\Seth_MatchPennies_Agent_Exp1')\n",
    "PATH = os.getcwd()\n",
    "figures_pull_list = []\n",
    "fields_pull = []\n",
    "with open(PATH+\"\\\\Figures_Pull_List.txt\", \"r\") as pull_file:\n",
    "    figures_pull_list = pull_file.read().splitlines()\n",
    "with open(PATH+\"\\\\Fields_Pull.txt\", \"r\") as fields_pull:\n",
    "    fields_pull = fields_pull.read().splitlines()\n",
    "NUM_SUBJECTS = len(figures_pull_list)\n",
    "task_name = 'Seth_MatchPennies_Agent_Exp1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dill Load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dill Load Control Tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub1\n",
      "Sub2\n",
      "Sub3\n",
      "Sub4\n",
      "Sub5\n",
      "Sub6\n",
      "Sub7\n",
      "Sub8\n",
      "Sub9\n",
      "Sub10\n",
      "Sub11\n",
      "Sub12\n",
      "Sub13\n",
      "Sub14\n",
      "Sub15\n",
      "Sub16\n",
      "Sub17\n",
      "Sub18\n",
      "Sub19\n",
      "Sub20\n"
     ]
    }
   ],
   "source": [
    "coincidence_trials = 50\n",
    "reaction_trials = 50\n",
    "interval_trials = 50\n",
    "# ---------------Controls-------------------------\n",
    "player_reaction_decision_array         = np.empty((NUM_SUBJECTS, reaction_trials))\n",
    "agent_reaction_decision_array          = np.empty((NUM_SUBJECTS, reaction_trials))\n",
    "player_reaction_time                   = np.zeros([NUM_SUBJECTS,reaction_trials])*np.nan \n",
    "player_reaction_movement_time          = np.zeros([NUM_SUBJECTS,reaction_trials])*np.nan\n",
    "player_reaction_plus_movement_time     = np.zeros([NUM_SUBJECTS,reaction_trials])*np.nan\n",
    "reaction_trial_start                   = np.zeros((NUM_SUBJECTS,reaction_trials))*np.nan \n",
    "coincidence_trial_start                = np.zeros((NUM_SUBJECTS, coincidence_trials))*np.nan\n",
    "coincidence_reach_time                 = np.zeros((NUM_SUBJECTS, coincidence_trials))*np.nan\n",
    "interval_trial_start                   = np.zeros((NUM_SUBJECTS, interval_trials))*np.nan\n",
    "interval_reach_time                    = np.zeros((NUM_SUBJECTS, interval_trials))*np.nan\n",
    "\n",
    "for i in range(NUM_SUBJECTS):\n",
    "    subname = figures_pull_list[i]\n",
    "    data_path = PATH+f'\\\\Subjects_Analyzed\\\\{subname}\\\\'\n",
    "    reaction_trial_start[i,:]                = dill.load(open(data_path + f'{subname}_reaction_trial_start.pkl', 'rb'))\n",
    "    player_reaction_time[i,:]                = dill.load(open(data_path + f'{subname}_player_reaction_time.pkl', 'rb'))\n",
    "    player_reaction_movement_time[i,:]       = dill.load(open(data_path + f'{subname}_player_reaction_movement_time.pkl', 'rb'))\n",
    "    player_reaction_plus_movement_time[i,:]  = dill.load(open(data_path + f'{subname}_player_reaction_plus_movement_time.pkl', 'rb'))\n",
    "    player_reaction_decision_array[i,:]      = dill.load(open(data_path + f'{subname}_player_reaction_decision_array.pkl', 'rb'))\n",
    "    agent_reaction_decision_array[i,:]       = dill.load(open(data_path + f'{subname}_agent_reaction_decision_time.pkl', 'rb'))\n",
    "    reaction_trial_start[i,:]                = dill.load(open(data_path + f'{subname}_reaction_trial_start.pkl', 'rb'))\n",
    "    interval_trial_start[i,:]                = dill.load(open(data_path + f'{subname}_interval_trial_start.pkl', 'rb'))\n",
    "    interval_reach_time[i,:]                 = dill.load(open(data_path + f'{subname}_interval_reach_time.pkl', 'rb'))\n",
    "    coincidence_trial_start[i,:]             = dill.load(open(data_path + f'{subname}_coincidence_trial_start.pkl', 'rb'))\n",
    "    coincidence_reach_time[i,:]              = dill.load(open(data_path + f'{subname}_coincidence_reach_time.pkl', 'rb'))\n",
    "    print(subname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dill Load Task and Washout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = PATH+'\\\\'+'Sub1_Task'\n",
    "task_df = pd.read_csv(path1+f'\\\\Sub1_TaskTrial_Table.csv')\n",
    "task_df = task_df.loc[task_df['Condition type']==3] # Only get the task condition \n",
    "num_trials = int(task_df.iloc[-1]['Block_Step']) # number of trials in each block\n",
    "num_blocks = int(task_df.iloc[-1]['Block_Row']/2)\n",
    "tot_trials = int(num_trials*num_blocks)\n",
    "trial_time = int(task_df.iloc[0]['Condition time'])\n",
    "task_df_columns = len(fields_pull)\n",
    "trial_table = np.empty((NUM_SUBJECTS, tot_trials, 4), int)\n",
    "#----------------- TASK--------------------------------\n",
    "player_task_reach_time       = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan \n",
    "player_task_decision_time    = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan \n",
    "player_task_decision_array   = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan\n",
    "player_task_movement_time    = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan\n",
    "agent_task_reach_time        = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan \n",
    "agent_task_decision_time     = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan \n",
    "agent_task_decision_array    = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan\n",
    "\n",
    "# -------------- Washout-------------------\n",
    "washout_trials = 25\n",
    "player_washout_reach_time      = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan \n",
    "player_washout_decision_time   = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan \n",
    "player_washout_decision_array  = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan\n",
    "player_washout_movement_time   = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan\n",
    "agent_washout_reach_time       = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan \n",
    "agent_washout_decision_time    = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan \n",
    "agent_washout_decision_array   = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan\n",
    "agent_washout_movement_time    = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan\n",
    "\n",
    "for i in range(NUM_SUBJECTS):\n",
    "    subname = figures_pull_list[i]\n",
    "    data_path = PATH+f'\\\\Subjects_Analyzed\\\\{subname}\\\\'\n",
    "    #task_data[i,:,:,:,:] = dill.load(open(data_path + f'{subname}_task_data.pkl', 'rb'))\n",
    "    player_task_decision_time[i,:,:]      = dill.load( open(data_path + f'{subname}_player_task_decision_time.pkl', 'rb'))\n",
    "    player_task_decision_array[i,:,:]     = dill.load( open(data_path + f'{subname}_player_task_decision_array.pkl', 'rb'))\n",
    "    player_task_movement_time[i,:,:]      = dill.load(open(data_path + f'{subname}_player_task_movement_time.pkl', 'rb'))\n",
    "    player_task_reach_time[i,:,:]         = dill.load( open(data_path + f'{subname}_player_task_reach_time.pkl', 'rb'))\n",
    "    agent_task_decision_time[i,:,:]       = dill.load( open(data_path + f'{subname}_agent_task_decision_time.pkl', 'rb'))\n",
    "    agent_task_decision_array[i,:,:]      = dill.load(open(data_path + f'{subname}_agent_task_decision_array.pkl', 'rb'))\n",
    "    agent_task_reach_time[i,:,:]          = agent_task_decision_time[i,:,:] + 150\n",
    "    player_washout_decision_time[i,:,:]   = dill.load( open(data_path + f'{subname}_player_washout_decision_time.pkl', 'rb'))\n",
    "    player_washout_decision_array[i,:,:]  = dill.load( open(data_path + f'{subname}_player_washout_decision_array.pkl', 'rb'))\n",
    "    player_washout_movement_time[i,:,:]   = dill.load(open(data_path + f'{subname}_player_washout_movement_time.pkl', 'rb'))\n",
    "    player_washout_reach_time[i,:,:]      = dill.load( open(data_path + f'{subname}_player_washout_reach_time.pkl', 'rb'))\n",
    "    agent_washout_decision_time[i,:,:]    = dill.load( open(data_path + f'{subname}_agent_washout_decision_time.pkl', 'rb'))\n",
    "    agent_washout_decision_array[i,:,:]   = dill.load(open(data_path + f'{subname}_agent_washout_decision_array.pkl', 'rb'))\n",
    "    agent_washout_reach_time[i,:,:]       = dill.load(open(data_path + f'{subname}_agent_washout_reach_time.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Subject Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Exp1\\Scripts\\Analysis_and_Statistics\\Subject_Object.py:324: RuntimeWarning: Mean of empty slice\n",
      "  self.player_reaction_decision_time_mean                     = np.nanmean(self.player_reaction_decision_time, axis = 1 )\n",
      "c:\\Users\\Seth Sullivan\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1878: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Exp1\\Scripts\\Analysis_and_Statistics\\Subject_Object.py:327: RuntimeWarning: Mean of empty slice\n",
      "  self.agent_task_decision_time_reaction_mean                 = np.nanmean(self.agent_reaction_decision_time, axis = 1)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Exp1\\Scripts\\Analysis_and_Statistics\\Subject_Object.py:328: RuntimeWarning: Mean of empty slice\n",
      "  self.player_minus_agent_player_reaction_decision_time_mean  = np.nanmean(self.player_minus_agent_player_reaction_decision_time, axis = 1)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Exp1\\Scripts\\Analysis_and_Statistics\\Subject_Object.py:409: RuntimeWarning: Mean of empty slice\n",
      "  self.binned_player_task_decision_times_mean            = np.nanmean(self.binned_player_task_decision_times,axis=2) # Mean for each bin, each condition\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Exp1\\Scripts\\Analysis_and_Statistics\\Subject_Object.py:410: RuntimeWarning: Mean of empty slice\n",
      "  self.binned_player_minus_agent_task_decision_time_mean = np.nanmean(self.binned_player_minus_agent_task_decision_time,axis=2)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Exp1\\Scripts\\Analysis_and_Statistics\\Subject_Object.py:154: RuntimeWarning: Mean of empty slice\n",
      "  self.agent_mean_task_decision_time_on_incorrects   = np.nanmean(self.agent_task_decision_time_on_incorrects,axis=1)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Exp1\\Scripts\\Analysis_and_Statistics\\Subject_Object.py:177: RuntimeWarning: Mean of empty slice\n",
      "  self.player_mean_task_decision_time_on_incorrects   = np.nanmean(self.player_task_decision_time_on_incorrects,axis=1)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Exp1\\Scripts\\Analysis_and_Statistics\\Subject_Object.py:184: RuntimeWarning: Mean of empty slice\n",
      "  self.player_mean_task_reach_time_on_incorrects      = np.nanmean(self.player_task_reach_time_on_incorrects,axis=1)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Exp1\\Scripts\\Analysis_and_Statistics\\Subject_Object.py:152: RuntimeWarning: Mean of empty slice\n",
      "  self.agent_mean_task_decision_time_on_indecisions  = np.nanmean(self.agent_task_decision_time_on_indecisions,axis=1)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Exp1\\Scripts\\Analysis_and_Statistics\\Subject_Object.py:175: RuntimeWarning: Mean of empty slice\n",
      "  self.player_mean_task_decision_time_on_indecisions  = np.nanmean(self.player_task_decision_time_on_indecisions,axis=1)\n",
      "c:\\Users\\Seth Sullivan\\OneDrive - University of Delaware - o365\\Desktop\\MatchPennies-Agent-Expirement\\Exp1\\Scripts\\Analysis_and_Statistics\\Subject_Object.py:182: RuntimeWarning: Mean of empty slice\n",
      "  self.player_mean_task_reach_time_on_indecisions     = np.nanmean(self.player_task_reach_time_on_indecisions,axis=1)\n"
     ]
    }
   ],
   "source": [
    "path1 = PATH+'\\\\'+'Sub1_Task'\n",
    "task_df = pd.read_csv(path1+f'\\\\Sub1_TaskTrial_Table.csv')\n",
    "task_df = task_df.loc[task_df['Condition type']==3] # Only get the task condition \n",
    "num_trials = int(task_df.iloc[-1]['Block_Step']) # number of trials in each block\n",
    "num_blocks = int(task_df.iloc[-1]['Block_Row']/2)\n",
    "tot_trials = int(num_trials*num_blocks)\n",
    "trial_time = int(task_df.iloc[0]['Condition time'])\n",
    "task_df_columns = len(fields_pull)\n",
    "trial_table = np.empty((NUM_SUBJECTS, tot_trials, 4), int)\n",
    "#----------------- TASK--------------------------------\n",
    "player_task_reach_time = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan \n",
    "player_task_decision_time = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan \n",
    "player_task_decision_array = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan\n",
    "player_task_movement_time = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan\n",
    "agent_task_reach_time = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan \n",
    "agent_task_decision_time = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan \n",
    "agent_task_decision_array = np.zeros([NUM_SUBJECTS,num_blocks,num_trials])*np.nan\n",
    "\n",
    "# -------------- Washout-------------------\n",
    "washout_trials = 25\n",
    "player_washout_reach_time = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan \n",
    "player_washout_decision_time = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan \n",
    "player_washout_decision_array = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan\n",
    "player_washout_movement_time = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan\n",
    "agent_washout_reach_time = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan \n",
    "agent_washout_decision_time = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan \n",
    "agent_washout_decision_array = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan\n",
    "agent_washout_movement_time = np.zeros([NUM_SUBJECTS,num_blocks,washout_trials])*np.nan\n",
    "\n",
    "for i in range(NUM_SUBJECTS):\n",
    "    subname = figures_pull_list[i]\n",
    "    data_path = PATH+f'\\\\Subjects_Analyzed\\\\{subname}\\\\'\n",
    "    #task_data[i,:,:,:,:] = dill.load(open(data_path + f'{subname}_task_data.pkl', 'rb'))\n",
    "    player_task_decision_time[i,:,:] = dill.load(open(data_path + f'{subname}_player_task_decision_time.pkl', 'rb'))\n",
    "    player_task_decision_array[i,:,:] = dill.load(open(data_path + f'{subname}_player_task_decision_array.pkl', 'rb'))\n",
    "    player_task_movement_time[i,:,:] = dill.load(open(data_path + f'{subname}_player_task_movement_time.pkl', 'rb'))\n",
    "    player_task_reach_time[i,:,:] = dill.load(open(data_path + f'{subname}_player_task_reach_time.pkl', 'rb'))\n",
    "    agent_task_decision_time[i,:,:] = dill.load(open(data_path + f'{subname}_agent_task_decision_time.pkl', 'rb'))\n",
    "    agent_task_decision_array[i,:,:] = dill.load(open(data_path + f'{subname}_agent_task_decision_array.pkl', 'rb'))\n",
    "    agent_task_reach_time[i,:,:] = agent_task_decision_time[i,:,:] + 150\n",
    "    player_washout_decision_time[i,:,:] = dill.load(open(data_path + f'{subname}_player_washout_decision_time.pkl', 'rb'))\n",
    "    player_washout_decision_array[i,:,:] = dill.load(open(data_path + f'{subname}_player_washout_decision_array.pkl', 'rb'))\n",
    "    player_washout_movement_time[i,:,:] = dill.load(open(data_path + f'{subname}_player_washout_movement_time.pkl', 'rb'))\n",
    "    player_washout_reach_time[i,:,:] = dill.load(open(data_path + f'{subname}_player_washout_reach_time.pkl', 'rb'))\n",
    "    agent_washout_decision_time[i,:,:] = dill.load(open(data_path + f'{subname}_agent_washout_decision_time.pkl', 'rb'))\n",
    "    agent_washout_decision_array[i,:,:] = dill.load(open(data_path + f'{subname}_agent_washout_decision_array.pkl', 'rb'))\n",
    "    agent_washout_reach_time[i,:,:] = dill.load(open(data_path + f'{subname}_agent_washout_reach_time.pkl', 'rb'))\n",
    "\n",
    "NUM_STDS = [0,1,2]\n",
    "append_dict = {0:'reaction_time_no_sd_off',1:'reaction_time_minus_sd',2:'reaction_time_minus_2sd'}\n",
    "data_path = 'D:\\\\Subject_Data\\\\Seth_MatchPennies_Agent_Exp1\\\\Subjects_Analyzed\\\\'\n",
    "for sd in NUM_STDS:\n",
    "    subject_object_dict = {}\n",
    "    for i in range(NUM_SUBJECTS):\n",
    "        subname = figures_pull_list[i]\n",
    "        subject_object = Subject(num_trials = 80, num_blocks = 6, num_control_trials = 50, num_washout_trials = 25, reaction_time = player_reaction_time[i], reaction_movement_time = player_reaction_movement_time[i],reaction_plus_movement_time = player_reaction_plus_movement_time[i],\n",
    "                                    interval_trial_start = interval_trial_start[i], interval_reach_time = interval_reach_time[i], coincidence_trial_start = coincidence_trial_start[i], coincidence_reach_time = coincidence_reach_time[i],\n",
    "                                    player_task_reach_time = player_task_reach_time[i], player_task_decision_time = player_task_decision_time[i], player_task_decision_array = player_task_decision_array[i],\n",
    "                                    player_task_movement_time = player_task_movement_time[i], agent_task_reach_time = agent_task_reach_time[i], agent_task_decision_time = agent_task_decision_time[i], agent_task_decision_array = agent_task_decision_array[i],\n",
    "                                    player_washout_reach_time = player_washout_reach_time[i], player_washout_decision_time = player_washout_decision_time[i], player_washout_decision_array = player_washout_decision_array[i],\n",
    "                                    player_washout_movement_time = player_washout_movement_time[i], agent_washout_reach_time = agent_washout_reach_time[i], agent_washout_decision_time = agent_washout_decision_time[i], agent_washout_decision_array = agent_washout_decision_array[i],\n",
    "                                    num_stds_for_reaction_time = sd\n",
    "                                    )\n",
    "        subject_object.analyze_data(0) # The number in this function is the cutoff value (in the future, not done yet)\n",
    "        subject_object_dict.update({subname:subject_object})\n",
    "        \n",
    "        dill.dump(subject_object_dict[subname], open(data_path + f'{subname}\\\\{subname}_object_{append_dict[sd]}.pkl', 'wb'))\n",
    "    dill.dump(subject_object_dict,open(data_path + f'subject_object_{append_dict[sd]}_dict.pkl', 'wb'))\n",
    "\n",
    "    group = Group(list(subject_object_dict.values()))\n",
    "    dill.dump(group,open(data_path + f'group_object_{append_dict[sd]}.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0,1],[2,1]],dtype=float)\n",
    "mask = a==1\n",
    "a[~mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "b = np.array([3,2,3,0])\n",
    "mask = a == 1\n",
    "c = b*mask\n",
    "c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a00c1525417994d84940f6a64b96d4df953e4f0863c4f32c2c802abdf8195ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
